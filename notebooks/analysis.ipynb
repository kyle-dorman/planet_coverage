{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997513c2-5c95-4bb9-944e-c1d7379903d8",
   "metadata": {},
   "source": [
    "# DuckDB + Parquet Data Exploration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a8991d-9b51-4869-8aa1-7199bd7cc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from branca.colormap import linear\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "from src.util import create_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8fff9-14d0-46f0-86a6-826aa299b5f8",
   "metadata": {},
   "source": [
    "# --- Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d7d488-22fa-4e4f-8f03-75b024e60d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE = Path(\"/Users/kyledorman/data/planet_coverage/ca_only\")  # <-- update this\n",
    "config_file = BASE / \"dove\" / \"config.yaml\"  # <-- update this\n",
    "config = create_config(config_file)\n",
    "\n",
    "# Example path patterns\n",
    "f_pattern = \"*/coastal_results/*/*/*/coastal_points.parquet\"\n",
    "all_files_pattern = str(BASE / f_pattern)\n",
    "\n",
    "# Combined list used later when we search individual files\n",
    "all_parquets = list(BASE.glob(f_pattern))\n",
    "\n",
    "len(all_parquets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c7198d-935b-491e-aac7-436855fa5e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_ocean = gpd.read_file(BASE.parent / \"shorelines\" / \"ca_ocean.geojson\")\n",
    "ca_ocean.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f78e9-07c5-4468-98d7-3667c1958238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base map centered on the calculated location\n",
    "ca_ocean = gpd.read_file(BASE / \"ca_ocean.geojson\")\n",
    "query_df = gpd.read_file(BASE / \"ocean_grids.gpkg\").to_crs(ca_ocean.crs)\n",
    "grids_df = gpd.read_file(BASE / \"coastal_grids.gpkg\").to_crs(ca_ocean.crs).rename(columns={\"cell_id\": \"grid_id\"})\n",
    "\n",
    "query_ca = query_df[query_df.geometry.intersects(ca_ocean.union_all())]\n",
    "\n",
    "grids_ca = grids_df[grids_df.geometry.intersects(ca_ocean.union_all())]\n",
    "\n",
    "len(grids_ca), len(query_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480c470-81a9-46ad-8025-1c48449dfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base map centered on the calculated location\n",
    "centroid = ca_ocean.geometry[0].centroid\n",
    "base_map = folium.Map(location=[centroid.y, centroid.x], zoom_start=5, width=1000, height=800)\n",
    "\n",
    "for idx, geo in enumerate(ca_ocean.geometry):\n",
    "    folium.GeoJson(\n",
    "        geo,\n",
    "        name=str(idx),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"red\",\n",
    "            \"weight\": 4,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "# # Add each GeoJSON file to the map\n",
    "# # Add polygons to the map\n",
    "for _, row in query_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(row[\"cell_id\"]),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"blue\",\n",
    "            \"weight\": 2,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "for _, row in grids_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(row[\"grid_id\"]),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"green\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "# Display the map\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929171dd-9ced-4508-b24a-cf1c6c1b3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect to DuckDB ---\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72609db-73e0-412f-bc32-7c2b032c1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = None\n",
    "\n",
    "for seach_index in grids_ca.grid_id:\n",
    "    if FILE is not None:\n",
    "        break\n",
    "    for file in all_parquets:\n",
    "        result = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM read_parquet('{file}') WHERE grid_id = {seach_index}\"\n",
    "        ).fetchone()\n",
    "    \n",
    "        if len(result) and result[0] > 0:\n",
    "            print(f\"Found grid_id {seach_index} in: {file}\")\n",
    "            FILE = file\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7262dee-6b6f-4fa2-ad49-d84fc7b20173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for all files\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_all AS\n",
    "    SELECT * FROM read_parquet('{all_files_pattern}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdecbcf-919b-4c11-93b3-03dd314cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for a single file for faster iteration\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_one AS\n",
    "    SELECT * FROM '{FILE}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07135270-ac2b-4a82-8477-d26dc4c18fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schema Inspection ---\n",
    "print(\"Schema of samples_one:\")\n",
    "df = con.execute(\"DESCRIBE samples_one\").fetchdf()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b97d49-1f5c-4497-8676-84d45d412eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NULL Check ---\n",
    "print(\"Checking for NULL values:\")\n",
    "df_nulls = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN id IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
    "        SUM(CASE WHEN acquired IS NULL THEN 1 ELSE 0 END) AS null_acquired,\n",
    "        SUM(CASE WHEN item_type IS NULL THEN 1 ELSE 0 END) AS null_item_type,\n",
    "        SUM(CASE WHEN satellite_id IS NULL THEN 1 ELSE 0 END) AS null_satellite_id,\n",
    "        SUM(CASE WHEN instrument IS NULL THEN 1 ELSE 0 END) AS null_instrument,\n",
    "\n",
    "        SUM(CASE WHEN cell_id IS NULL THEN 1 ELSE 0 END) AS null_cell_id,\n",
    "        SUM(CASE WHEN grid_id IS NULL THEN 1 ELSE 0 END) AS null_grid_id,\n",
    "        \n",
    "        SUM(CASE WHEN has_8_channel IS NULL THEN 1 ELSE 0 END) AS null_has_8_channel,\n",
    "        SUM(CASE WHEN has_sr_asset IS NULL THEN 1 ELSE 0 END) AS null_has_sr_asset,\n",
    "        SUM(CASE WHEN clear_percent IS NULL THEN 1 ELSE 0 END) AS null_clear_percent,\n",
    "        SUM(CASE WHEN quality_category IS NULL THEN 1 ELSE 0 END) AS null_quality_category,\n",
    "        SUM(CASE WHEN ground_control IS NULL THEN 1 ELSE 0 END) AS null_ground_control,\n",
    "        SUM(CASE WHEN publishing_stage IS NULL THEN 1 ELSE 0 END) AS null_publishing_stage,\n",
    "        \n",
    "        SUM(CASE WHEN satellite_azimuth IS NULL THEN 1 ELSE 0 END) AS null_satellite_azimuth,\n",
    "        SUM(CASE WHEN sun_azimuth IS NULL THEN 1 ELSE 0 END) AS null_sun_azimuth,\n",
    "        SUM(CASE WHEN sun_elevation IS NULL THEN 1 ELSE 0 END) AS null_sun_elevation,\n",
    "        SUM(CASE WHEN view_angle IS NULL THEN 1 ELSE 0 END) AS null_view_angle,\n",
    "        SUM(CASE WHEN coverage_pct IS NULL THEN 1 ELSE 0 END) AS null_coverage_pct,\n",
    "    FROM samples_one\n",
    "\"\"\").fetchdf()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890dfc09-9521-4213-a778-f0359ef11f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['item_type', 'instrument', 'has_8_channel ', 'has_sr_asset', 'quality_category', 'ground_control', 'publishing_stage']\n",
    "for col in cols:\n",
    "    df = con.execute(f\"SELECT DISTINCT {col} from samples_all\").fetchdf()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1766df-3275-4e85-914e-6a8c61e0f2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['item_type', 'instrument', 'has_8_channel ', 'has_sr_asset', 'quality_category', 'ground_control', 'publishing_stage']\n",
    "for col in cols:\n",
    "    df = con.execute(f\"SELECT DISTINCT {col} from samples_one\").fetchdf()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19424005-c171-4b68-ac72-e4031acfd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preview Data ---\n",
    "df_preview = con.execute(\"SELECT * FROM samples_one LIMIT 10\").fetchdf()\n",
    "display(df_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a902c96-bc05-4307-b768-208cbf6e66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Count Rows ---\n",
    "print(\"Total rows in sample file:\")\n",
    "print(con.execute(\"SELECT COUNT(*) FROM samples_one\").fetchone()[0])\n",
    "\n",
    "# --- Count Rows ---\n",
    "print(\"Total rows all files:\")\n",
    "print(con.execute(\"SELECT COUNT(*) FROM samples_all\").fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74743f6e-154a-4279-90bc-395e27edaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter By Time ---\n",
    "df_2024 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM samples_one\n",
    "    WHERE acquired >= '2024-01-01' AND acquired < '2025-01-01'\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "display(df_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101d648-fc96-4a1f-a244-2f26cf323747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, column_name, title, radius=6):\n",
    "    # --- Folium map for % ---\n",
    "    if df[column_name].max() == df[column_name].min():\n",
    "        scale_min = 0\n",
    "    else:\n",
    "        scale_min = df[column_name].min()\n",
    "    color_scale = linear.viridis.scale(scale_min, df[column_name].max())\n",
    "    \n",
    "    m = folium.Map(\n",
    "        location=[df.geometry.centroid.y.mean(), df.geometry.centroid.x.mean()], \n",
    "        zoom_start=5, \n",
    "        tiles=\"CartoDB positron\",\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        value = row[column_name]\n",
    "        centroid = row.geometry.centroid\n",
    "        folium.CircleMarker(\n",
    "            location=[centroid.y, centroid.x],\n",
    "            radius=radius,\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            color=None,\n",
    "            fill_color=color_scale(value),\n",
    "            popup=f\"Grid ID: {row.name}<br>{column_name}: {value:.2f}\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    color_scale.caption = title\n",
    "    color_scale.add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "def plot_bool_pct(column_name, bool_logic_str, merge_df, title, radius=6, nafill = 0.0):\n",
    "    df_pct = con.execute(\n",
    "        f\"\"\"\n",
    "        SELECT grid_id,\n",
    "               SUM({bool_logic_str})::DOUBLE  / COUNT(*) AS frac_{column_name}\n",
    "        FROM samples_all\n",
    "        WHERE item_type = 'PSScene'\n",
    "        GROUP BY grid_id\n",
    "    \"\"\"\n",
    "    ).fetchdf()\n",
    "\n",
    "    geo_pct = merge_df.set_index(\"grid_id\").join(df_pct.set_index(\"grid_id\"), how=\"left\").fillna({f\"frac_{column_name}\": nafill})\n",
    "\n",
    "    return plot_df(geo_pct, f\"frac_{column_name}\", title, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5c8f-5dbb-4de2-90fd-6f377556bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "geo_plot = grids_ca.set_index(\"grid_id\").join(df_counts.set_index(\"grid_id\"), how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "plot_df(geo_plot, \"sample_count\", \"Sample Count PSScene\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a3de4-7d51-476f-bceb-2dd906eb2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    AND coverage_pct > 0.5\n",
    "    AND publishing_stage = 'finalized'\n",
    "    AND quality_category = 'standard'\n",
    "    AND has_sr_asset\n",
    "    AND ground_control\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "geo_plot = grids_ca.set_index(\"grid_id\").join(df_counts.set_index(\"grid_id\"), how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "plot_df(geo_plot, \"sample_count\", \"High Quality Sample Count\", radius=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497b136-bbf1-4abf-b565-2c9f10eaa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram Per Day Counts (w/Publish Stage) ---- #\n",
    "\n",
    "# 1. Pull per-day counts broken out by stage\n",
    "df_stage = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        date_trunc('day', acquired) AS day,\n",
    "        publishing_stage,\n",
    "        COUNT(DISTINCT id) AS cnt\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY day, publishing_stage\n",
    "    ORDER BY day\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# 2. Normalize day column and pivot so each stage is its own column\n",
    "df_stage['day'] = pd.to_datetime(df_stage['day']).dt.date\n",
    "df_pivot = (\n",
    "    df_stage\n",
    "    .pivot(index='day', columns='publishing_stage', values='cnt')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 3. Ensure a consistent stack order\n",
    "stages = ['preview', 'finalized', 'standard']\n",
    "df_pivot = df_pivot.reindex(columns=stages, fill_value=0)\n",
    "\n",
    "# 4. Plot stacked bars\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "bottom = np.zeros(len(df_pivot))\n",
    "\n",
    "for stage in stages:\n",
    "    ax.bar(\n",
    "        df_pivot.index.astype(str),\n",
    "        df_pivot[stage],\n",
    "        bottom=bottom,\n",
    "        label=stage\n",
    "    )\n",
    "    bottom += df_pivot[stage].values\n",
    "\n",
    "ax.set_xticklabels(df_pivot.index.astype(str), rotation=45, ha='right')\n",
    "ax.set_title(\"Sample Count per Day by Publishing Stage\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"Sample Count\")\n",
    "ax.legend(title=\"Publishing Stage\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d116df9-8fe2-4519-8488-4cdabc72e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minmax(column: str) -> pd.DataFrame:\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "        MIN({column}) AS minv,\n",
    "        MAX({column}) AS maxv\n",
    "        FROM samples_all\n",
    "        WHERE item_type = 'PSScene'\n",
    "    \"\"\"\n",
    "    return con.execute(sql).fetchdf()\n",
    "\n",
    "def compute_histogram(column: str, nbins: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs DuckDB's histogram() table function on `column` in samples_all (filtered to PSScene)\n",
    "    and returns a DataFrame with columns: bin_upper, frequency.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        WITH bounds AS (\n",
    "          SELECT\n",
    "            MIN({column}) AS mn,\n",
    "            MAX({column}) AS mx\n",
    "          FROM samples_all\n",
    "          WHERE item_type = 'PSScene'\n",
    "        )\n",
    "        SELECT\n",
    "          -- histogram() returns a MAP<upper_boundary, count>\n",
    "          histogram(\n",
    "            {column},\n",
    "            equi_width_bins(bounds.mn::DOUBLE, bounds.mx::DOUBLE, {nbins}::BIGINT, True)\n",
    "          ) AS hist_map\n",
    "        FROM samples_all\n",
    "        CROSS JOIN bounds\n",
    "        WHERE item_type = 'PSScene';\n",
    "    \"\"\"\n",
    "    hist_map = con.execute(sql).fetchdf().iloc[0][\"hist_map\"]\n",
    "\n",
    "    \n",
    "    # Unpack into a two-column DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'bin_upper': list(hist_map.keys()),\n",
    "        'count':     list(hist_map.values())\n",
    "    })\n",
    "    df = df.sort_values('bin_upper').reset_index(drop=True)\n",
    "    uppers = df['bin_upper'].tolist()\n",
    "    bin_size = uppers[1] - uppers[0]\n",
    "    # Compute lower edge from previous upper\n",
    "    lowest = uppers[0] - bin_size\n",
    "    lowers = [lowest] + uppers[:-1]\n",
    "    df[\"bin_lower\"] = pd.Series(lowers)\n",
    "    df[\"centers\"] = (df[\"bin_lower\"] + df['bin_upper']) / 2\n",
    "    df[\"widths\"]  = df['bin_upper'] - df[\"bin_lower\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a1c51-6cc6-4b48-84ff-208eaa737f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 2×2 grid of histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# 2. Plotting all four angle columns\n",
    "for ax, col in zip(axes, [\"satellite_azimuth\", \"sun_azimuth\", \"sun_elevation\", \"view_angle\"]):\n",
    "    df_hist = compute_histogram(col, nbins=30)\n",
    "\n",
    "    ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "    ax.set_title(f\"Histogram of {col.replace('_',' ').title()}\")\n",
    "    ax.set_xlabel(col.replace('_',' ').title())\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05745a81-42e9-4ff2-b7e1-9f9f1ee79912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of Sample Count per Month ---\n",
    "df_monthly = con.execute(\"\"\"\n",
    "    SELECT date_trunc('month', acquired) AS month, COUNT(DISTINCT id) AS sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(df_monthly['month'].astype(str), df_monthly['sample_count'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Sample Count per Month (Unique Scenes)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87f0de-daed-44b7-aa6d-41cae567ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of clear_percent ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"coverage_pct\", nbins=10)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'coverage_pct'.title()}\")\n",
    "ax.set_xlabel(\"coverage_pct\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd105d2-b778-467e-96c7-fa9cb0a9b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of clear_percent ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"clear_percent\", nbins=30)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'clear_percent'.title()}\")\n",
    "ax.set_xlabel(\"clear_percent\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8bcb49-91a3-4ac1-8be7-ec7813a254d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction of finalized per Grid Point ---\n",
    "plot_bool_pct(\n",
    "    'publishing_stage', \n",
    "    \"publishing_stage = 'finalized'\", \n",
    "    grids_ca, \n",
    "    \"Fraction of Finalized Observations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63891056-ef5d-4278-b43c-7ded3d117df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction of preview per Grid Point ---\n",
    "plot_bool_pct(\n",
    "    'publishing_stage', \n",
    "    \"publishing_stage = 'preview'\", \n",
    "    grids_ca,\n",
    "    \"Fraction of Preview Observations\",\n",
    "    nafill=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68101a-e36d-4ec0-be32-2d3b7eec01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction of has_8_channel per Grid Point ---\n",
    "plot_bool_pct(\n",
    "    'has_8_channel', \n",
    "    \"has_8_channel\", \n",
    "    grids_ca, \n",
    "    \"Fraction of 8-Channel Observations\",\n",
    "    nafill=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde5d5c-e503-4b52-933a-c442bad2ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction analysis ready data per Grid Point ---\n",
    "plot_bool_pct(\n",
    "    'has_sr_asset', \n",
    "    \"has_sr_asset\", \n",
    "    grids_ca, \n",
    "    \"Fraction of Analysis Ready Observations\",\n",
    "    nafill=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a13560-8456-40df-99ab-fbf35bfa2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction analysis ready data per Grid Point ---\n",
    "plot_bool_pct(\n",
    "    'ground_control', \n",
    "    \"ground_control\", \n",
    "    grids_ca, \n",
    "    \"Fraction of ground_control Observations\",\n",
    "    nafill=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd2e34-027a-4534-9170-f35d926ea52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(ground_control)::DOUBLE  / COUNT(*) AS frac_preview_gc\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene' AND publishing_stage = 'preview'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf()\n",
    "\n",
    "display(df_pct[df_pct.frac_preview_gc > 0.5].head())\n",
    "\n",
    "geo_pct = grids_ca.set_index(\"grid_id\").join(df_pct.set_index(\"grid_id\"), how=\"left\").fillna({\"frac_preview_gc\": 0.5})\n",
    "\n",
    "plot_df(\n",
    "    geo_pct, \n",
    "    \"frac_preview_gc\", \n",
    "    \"Fraction Preview Scenes w/Ground Control\", \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
