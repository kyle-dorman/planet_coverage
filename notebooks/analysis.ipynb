{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997513c2-5c95-4bb9-944e-c1d7379903d8",
   "metadata": {},
   "source": [
    "# DuckDB + Parquet Data Exploration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8991d-9b51-4869-8aa1-7199bd7cc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from branca.colormap import linear\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.util import make_cell_geom, create_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8fff9-14d0-46f0-86a6-826aa299b5f8",
   "metadata": {},
   "source": [
    "# --- Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7d488-22fa-4e4f-8f03-75b024e60d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"/Users/kyledorman/data/planet_coverage/dove/results_2023/\")  # <-- update this\n",
    "\n",
    "gpkg_path = Path(\"/Users/kyledorman/data/planet_coverage/points_in_coastal_strips.gpkg\")  # <-- update this\n",
    "\n",
    "config_file = Path(\"/Users/kyledorman/data/planet_coverage/dove/results_2023/config.yaml\")  # <-- update this\n",
    "config = create_config(config_file)\n",
    "\n",
    "# Example path patterns\n",
    "all_files_pattern = str(BASE / \"*/*/*/data.parquet\")\n",
    "all_parquets = list(BASE.glob(\"*/*/*/data.parquet\"))\n",
    "# Sort by file size (descending)\n",
    "single_file = max(all_parquets, key=lambda f: f.stat().st_size)\n",
    "\n",
    "single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83fce3-f4bc-4f5d-a284-46fec53924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use Cartopy's Natural Earth admin_1_states_provinces shapefile\n",
    "shp_path = shpreader.natural_earth(resolution='10m',\n",
    "                                   category='cultural',\n",
    "                                   name='admin_1_states_provinces')\n",
    "states = gpd.read_file(shp_path)\n",
    "\n",
    "# 2. Filter to California\n",
    "ca = states[(states['admin'] == 'United States of America') &\n",
    "            (states['name'] == 'California')]\n",
    "\n",
    "# 3. Project to CA Albers for buffering\n",
    "ca_proj = ca.to_crs(\"EPSG:3310\")\n",
    "\n",
    "# 4. Buffer by 20 km\n",
    "buffered = ca_proj.buffer(1e5)\n",
    "\n",
    "# 6. Convert to GeoSeries and back to WGS84\n",
    "square_wgs = gpd.GeoSeries([buffered.geometry.iloc[0]], crs=\"EPSG:3310\").to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef34cd-6a7b-4f2a-b526-f555d4695889",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_geo_df = gpd.read_file(gpkg_path)\n",
    "gdf = orig_geo_df.to_crs(epsg=4326)\n",
    "\n",
    "degree_size = config.degree_size\n",
    "gdf[\"lon_bin\"] = (np.floor(gdf.geometry.x / degree_size) * degree_size).astype(float)\n",
    "gdf[\"lat_bin\"] = (np.floor(gdf.geometry.y / degree_size) * degree_size).astype(float)\n",
    "gdf[\"grid_index\"] = gdf.index\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) group by cell and collect both points AND their original indices\n",
    "# ----------------------------------------------------------------------------\n",
    "grouped = (\n",
    "    gdf.groupby([\"lon_bin\", \"lat_bin\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"geometry\": list,  # list of Point geometries\n",
    "            \"grid_index\": list,  # list of original indices\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "grouped[\"cell_geom\"] = grouped[\"geometry\"].apply(make_cell_geom)  # type: ignore\n",
    "cells = gpd.GeoDataFrame(grouped, geometry=\"cell_geom\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480c470-81a9-46ad-8025-1c48449dfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base map centered on the calculated location\n",
    "centroid = square_wgs.geometry[0].centroid\n",
    "base_map = folium.Map(location=[centroid.y, centroid.x], zoom_start=5, width=1000, height=800)\n",
    "\n",
    "for idx, geo in enumerate(square_wgs):\n",
    "    folium.GeoJson(\n",
    "        geo,\n",
    "        name=str(idx),\n",
    "    ).add_to(base_map)\n",
    "\n",
    "# Add each GeoJSON file to the map\n",
    "# Add polygons to the map\n",
    "intersects = gdf.geometry.intersects(square_wgs.geometry.iloc[0])\n",
    "for idx, row in gdf[intersects].iterrows():\n",
    "    pt = row[\"geometry\"]\n",
    "    folium.CircleMarker(\n",
    "        location=[pt.y, pt.x],\n",
    "        radius=0.5,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.1,\n",
    "        popup=str(idx),\n",
    "    ).add_to(base_map)\n",
    "\n",
    "# Display the map\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929171dd-9ced-4508-b24a-cf1c6c1b3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect to DuckDB ---\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72609db-73e0-412f-bc32-7c2b032c1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = gdf[gdf.geometry.intersects(square_wgs.geometry.iloc[0])].index[0]\n",
    "\n",
    "for file in all_parquets:\n",
    "    result = con.execute(\n",
    "        f\"SELECT COUNT(*) FROM read_parquet('{file}') WHERE grid_idx = {search_idx}\"\n",
    "    ).fetchone()[0]\n",
    "\n",
    "    if result > 0:\n",
    "        print(f\"Found grid_idx {search_idx} in: {file}\")\n",
    "        single_file = file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7262dee-6b6f-4fa2-ad49-d84fc7b20173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for all files\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_all AS\n",
    "    SELECT * FROM '{all_files_pattern}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdecbcf-919b-4c11-93b3-03dd314cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for a single file for faster iteration\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_one AS\n",
    "    SELECT * FROM '{single_file}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07135270-ac2b-4a82-8477-d26dc4c18fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schema Inspection ---\n",
    "print(\"Schema of samples_one:\")\n",
    "print(con.execute(\"DESCRIBE samples_one\").fetchdf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b97d49-1f5c-4497-8676-84d45d412eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NULL Check ---\n",
    "print(\"Checking for NULL values:\")\n",
    "df_nulls = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN has_8_channel IS NULL THEN 1 ELSE 0 END) AS null_has_8_channel,\n",
    "        SUM(CASE WHEN id IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
    "        SUM(CASE WHEN acquired IS NULL THEN 1 ELSE 0 END) AS null_acquired,\n",
    "        SUM(CASE WHEN clear_percent IS NULL THEN 1 ELSE 0 END) AS null_clear_percent,\n",
    "        SUM(CASE WHEN item_type IS NULL THEN 1 ELSE 0 END) AS null_item_type,\n",
    "        SUM(CASE WHEN quality_category IS NULL THEN 1 ELSE 0 END) AS null_quality_category,\n",
    "        SUM(CASE WHEN satellite_azimuth IS NULL THEN 1 ELSE 0 END) AS null_satellite_azimuth,\n",
    "        SUM(CASE WHEN sun_azimuth IS NULL THEN 1 ELSE 0 END) AS null_sun_azimuth,\n",
    "        SUM(CASE WHEN sun_elevation IS NULL THEN 1 ELSE 0 END) AS null_sun_elevation,\n",
    "        SUM(CASE WHEN view_angle IS NULL THEN 1 ELSE 0 END) AS null_view_angle,\n",
    "        SUM(CASE WHEN instrument IS NULL THEN 1 ELSE 0 END) AS null_instrument,\n",
    "        SUM(CASE WHEN grid_idx IS NULL THEN 1 ELSE 0 END) AS null_grid_idx\n",
    "    FROM samples_one\n",
    "\"\"\").fetchdf()\n",
    "print(df_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19424005-c171-4b68-ac72-e4031acfd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preview Data ---\n",
    "df_preview = con.execute(\"SELECT * FROM samples_one LIMIT 10\").fetchdf()\n",
    "display(df_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a902c96-bc05-4307-b768-208cbf6e66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Count Rows ---\n",
    "print(\"Total rows in sample file:\")\n",
    "print(con.execute(\"SELECT COUNT(*) FROM samples_one\").fetchone()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74743f6e-154a-4279-90bc-395e27edaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter By Time ---\n",
    "df_2024 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM samples_one\n",
    "    WHERE acquired >= '2024-01-01' AND acquired < '2025-01-01'\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "display(df_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80649432-f142-4337-a8f4-bd96da3c53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which cell this file corresponds to by matching its grid_idx\n",
    "file_grid_idxs = con.execute(\"SELECT DISTINCT grid_idx FROM samples_one\").fetchdf()[\"grid_idx\"].tolist()\n",
    "cells_containing_file_data = cells[cells[\"grid_index\"].apply(lambda lst: any(idx in file_grid_idxs for idx in lst))]\n",
    "\n",
    "# Flatten all grid indices in the matched cell\n",
    "matching_indices = set(idx for lst in cells_containing_file_data[\"grid_index\"] for idx in lst)\n",
    "geo_filtered = gdf[gdf[\"grid_index\"].isin(matching_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5c8f-5dbb-4de2-90fd-6f377556bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_idx, COUNT(*) as sample_count\n",
    "    FROM samples_one\n",
    "    GROUP BY grid_idx\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "geo_plot = geo_filtered.join(df_counts.set_index(\"grid_idx\"), how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "# --- Create Folium Map of Sample Count ---\n",
    "if geo_plot.sample_count.max() == geo_plot.sample_count.min():\n",
    "    scale_min = 0\n",
    "else:\n",
    "    scale_min = geo_plot.sample_count.min()\n",
    "color_scale = linear.viridis.scale(scale_min, geo_plot.sample_count.max())\n",
    "m = folium.Map(\n",
    "    location=[geo_plot.geometry.y.mean(), geo_plot.geometry.x.mean()], \n",
    "    zoom_start=8, \n",
    "    tiles=\"CartoDB positron\",\n",
    "    width=500, \n",
    "    height=500\n",
    ")\n",
    "\n",
    "for _, row in geo_plot.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=3,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        color=None,\n",
    "        fill_color=color_scale(row.sample_count),\n",
    "        popup=f\"Grid ID: {row.name}<br>Samples: {row.sample_count}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "color_scale.caption = \"Sample Count\"\n",
    "color_scale.width = 300  # Wider legend\n",
    "color_scale.heght = 100  # Wider legend\n",
    "color_scale.add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05745a81-42e9-4ff2-b7e1-9f9f1ee79912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of Sample Count per Month ---\n",
    "df_monthly = con.execute(\"\"\"\n",
    "    SELECT date_trunc('month', acquired) AS month, COUNT(DISTINCT id) AS sample_count\n",
    "    FROM samples_one\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(df_monthly['month'].astype(str), df_monthly['sample_count'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Sample Count per Month (Unique Scenes)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68101a-e36d-4ec0-be32-2d3b7eec01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction of has_8_channel per Grid Point ---\n",
    "df_fraction_8ch = con.execute(\"\"\"\n",
    "    SELECT grid_idx,\n",
    "           COUNT(*) AS total,\n",
    "           SUM(CASE WHEN has_8_channel THEN 1 ELSE 0 END)::DOUBLE / COUNT(*) AS frac_8_channel\n",
    "    FROM samples_one\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_idx\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "geo_frac = geo_filtered.join(df_fraction_8ch.set_index(\"grid_idx\"), how=\"left\").fillna({\"frac_8_channel\": 0})\n",
    "\n",
    "# --- Folium map for 8-channel fraction ---\n",
    "color_scale_frac = linear.viridis.scale(0, 1)\n",
    "m2 = folium.Map(\n",
    "    location=[geo_frac.geometry.y.mean(), geo_frac.geometry.x.mean()], \n",
    "    zoom_start=8, \n",
    "    tiles=\"CartoDB positron\",\n",
    "    width=500,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "for _, row in geo_frac.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=3,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        color=None,\n",
    "        fill_color=color_scale_frac(row.frac_8_channel),\n",
    "        popup=f\"Grid ID: {row.name}<br>8-Chan Fraction: {row.frac_8_channel:.2f}\"\n",
    "    ).add_to(m2)\n",
    "\n",
    "color_scale_frac.caption = \"Fraction of 8-Channel Observations\"\n",
    "color_scale_frac.width = 300  # Wider legend\n",
    "color_scale_frac.add_to(m2)\n",
    "\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a02806-bd55-4186-8949-2d1e5364d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_instruments = con.execute(\"SELECT DISTINCT instrument FROM samples_one\").fetchdf()\n",
    "print(unique_instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5aab6-5061-494b-b91f-d8b53bf1ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fraction of has_8_channel per Grid Point ---\n",
    "df_fraction_8ch_all = con.execute(\"\"\"\n",
    "    SELECT grid_idx,\n",
    "           COUNT(*) AS total,\n",
    "           SUM(CASE WHEN has_8_channel THEN 1 ELSE 0 END)::DOUBLE / COUNT(*) AS frac_8_channel\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_idx\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "geo_frac = gdf.join(df_fraction_8ch_all.set_index(\"grid_idx\"), how=\"inner\")\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Optional: Plot world basemap\n",
    "# world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "# world.plot(ax=ax, color='lightgray', edgecolor='white')\n",
    "\n",
    "# Plot points with frac_8_channel shading\n",
    "geo_frac.plot(\n",
    "    ax=ax,\n",
    "    column=\"frac_8_channel\",\n",
    "    cmap=\"plasma\",\n",
    "    markersize=10,\n",
    "    legend=True,\n",
    "    vmin=0.5,  # Force lower bound\n",
    "    vmax=1.0,  # Force upper bound\n",
    "    legend_kwds={\n",
    "        \"label\": \"Fraction of 8-Channel Observations\",\n",
    "        \"shrink\": 0.7,\n",
    "        \"orientation\": \"vertical\"\n",
    "    }\n",
    ")\n",
    "\n",
    "ax.set_title(\"Fraction of 8-Channel Observations per Grid Point\", fontsize=14)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb4df1-0708-4d5c-abbd-1b5d02910d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
