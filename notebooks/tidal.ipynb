{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e0e315-9951-4944-9641-78c9bd136616",
   "metadata": {},
   "source": [
    "# Tidal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03bb9dbf-f5c6-4108-9e64-338a07a863db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "from src.util import create_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e1ed8c-3881-4d73-90fe-2ac309ea7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"/Users/kyledorman/data/planet_coverage/ca_only/\")  # <-- update this\n",
    "config_file = BASE / \"dove\" / \"config.yaml\"  # <-- update this\n",
    "config = create_config(config_file)\n",
    "\n",
    "GRID_ID = 31565\n",
    "hex_id = f\"{GRID_ID:06x}\"  # unique 6‑digit hex, e.g. '0f1a2b'\n",
    "d1, d2, d3 = hex_id[:2], hex_id[2:4], hex_id[4:6]\n",
    "GRID_PATH = BASE / \"dove\" / \"results\" / \"2023\" / d1 / d2 / d3\n",
    "FILE_PATH = GRID_PATH / \"data.parquet\"\n",
    "\n",
    "assert FILE_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7a6430-824a-40a2-9301-f2e135057741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base map centered on the calculated location\n",
    "ca_ocean = gpd.read_file(BASE / \"ca_ocean.geojson\")\n",
    "all_grids_df = gpd.read_file(BASE / \"ocean_grids.gpkg\")\n",
    "tide_df = pd.read_csv(BASE / \"simulated_tidal_coverage.csv\")\n",
    "grid_df = all_grids_df[all_grids_df.cell_id.isin(tide_df.cell_id)].to_crs(ca_ocean.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f89800-e8a0-4809-a862-0f794d5cbbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x15693be70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Connect to DuckDB ---\n",
    "con = duckdb.connect()\n",
    "# Register a view for a single file for faster iteration\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_one AS\n",
    "    SELECT * FROM '{FILE_PATH}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22814e-7997-4cda-bccc-0ae937016ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = con.execute(\"SELECT * FROM samples_one\").fetchdf()\n",
    "\n",
    "print(len(sample_df))\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import ephem\n",
    "from ephem import Sun\n",
    "from datetime import datetime, time, timedelta, timezone\n",
    "\n",
    "def solartime(observer, sun):\n",
    "    sun.compute(observer)\n",
    "    # sidereal time == ra (right ascension) is the highest point (noon)\n",
    "    hour_angle = observer.sidereal_time() - sun.ra\n",
    "    return ephem.hours(hour_angle + ephem.hours('12:00')).norm  # norm for 24h\n",
    "\n",
    "sun = Sun()\n",
    "o = ephem.Observer()\n",
    "ts_utc = np.array(sample_df.acquired.dt.to_pydatetime())[0]\n",
    "o.date = ts_utc\n",
    "lon, lat = grid_df.geometry.iloc[0].centroid.x, grid_df.geometry.iloc[0].centroid.y\n",
    "o.lon = str(lon)\n",
    "o.lat = str(lat)\n",
    "\n",
    "print(o.next_transit(sun), ts_utc)\n",
    "\n",
    "ha = solartime(o, sun)\n",
    "print(\"ha\", ha)\n",
    "days = ha / 360\n",
    "print(days)\n",
    "if days > 0.5:\n",
    "    days -= 0.5\n",
    "td = timedelta(days=days)\n",
    "td.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e9383-b183-4301-922e-1ca072934da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_df = sample_df[\n",
    "    (sample_df['clear_percent'] > 80) & \n",
    "    (sample_df.publishing_stage == \"finalized\") &\n",
    "    (sample_df.quality_category == \"standard\") &\n",
    "    (sample_df.has_sr_asset) &\n",
    "    (sample_df.ground_control)\n",
    "]\n",
    "\n",
    "# 1) extract month numbers\n",
    "all_month = sample_df['acquired'].dt.month\n",
    "clear_month = clear_df['acquired'].dt.month\n",
    "\n",
    "# 2) count samples per month, ensure 1–12\n",
    "months = np.arange(1, 13)\n",
    "counts_all   = all_month.value_counts().reindex(months, fill_value=0).values\n",
    "counts_clear = clear_month.value_counts().reindex(months, fill_value=0).values\n",
    "\n",
    "# 3) determine shared y‐limit\n",
    "ymax = max(counts_all.max(), counts_clear.max()) * 1.1  # add 10% headroom\n",
    "\n",
    "# 4) plot side‐by‐side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "\n",
    "axes[0].bar(months, counts_all, width=0.8, edgecolor='black')\n",
    "axes[0].set_title('Samples per Month (All)')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks(months)\n",
    "axes[0].set_ylim(0, ymax)\n",
    "\n",
    "axes[1].bar(months, counts_clear, width=0.8, edgecolor='black')\n",
    "axes[1].set_title('Samples per Month (High Quality Samples)')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_xticks(months)\n",
    "axes[1].set_ylim(0, ymax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cc4ef-1a34-411d-9e73-6dd547aa5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minmax(column: str) -> pd.DataFrame:\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "        MIN({column}) AS minv,\n",
    "        MAX({column}) AS maxv\n",
    "        FROM samples_one\n",
    "    \"\"\"\n",
    "    return con.execute(sql).fetchdf()\n",
    "\n",
    "def compute_histogram(column: str, nbins: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs DuckDB's histogram() table function on `column` in samples_one (filtered to PSScene)\n",
    "    and returns a DataFrame with columns: bin_upper, frequency.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        WITH bounds AS (\n",
    "          SELECT\n",
    "            MIN({column}) AS mn,\n",
    "            MAX({column}) AS mx\n",
    "          FROM samples_one\n",
    "        )\n",
    "        SELECT\n",
    "          -- histogram() returns a MAP<upper_boundary, count>\n",
    "          histogram(\n",
    "            {column},\n",
    "            equi_width_bins(bounds.mn::DOUBLE, bounds.mx::DOUBLE, {nbins}::BIGINT, True)\n",
    "          ) AS hist_map\n",
    "        FROM samples_one\n",
    "        CROSS JOIN bounds;\n",
    "    \"\"\"\n",
    "    hist_map = con.execute(sql).fetchdf().iloc[0][\"hist_map\"]\n",
    "\n",
    "    \n",
    "    # Unpack into a two-column DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'bin_upper': list(hist_map.keys()),\n",
    "        'count':     list(hist_map.values())\n",
    "    })\n",
    "    df = df.sort_values('bin_upper').reset_index(drop=True)\n",
    "    uppers = df['bin_upper'].tolist()\n",
    "    bin_size = uppers[1] - uppers[0]\n",
    "    # Compute lower edge from previous upper\n",
    "    lowest = uppers[0] - bin_size\n",
    "    lowers = [lowest] + uppers[:-1]\n",
    "    df[\"bin_lower\"] = pd.Series(lowers)\n",
    "    df[\"centers\"] = (df[\"bin_lower\"] + df['bin_upper']) / 2\n",
    "    df[\"widths\"]  = df['bin_upper'] - df[\"bin_lower\"]\n",
    "    return df\n",
    "\n",
    "# Set up a 2×2 grid of histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# 2. Plotting all four angle columns\n",
    "for ax, col in zip(axes, [\"satellite_azimuth\", \"sun_azimuth\", \"sun_elevation\", \"view_angle\"]):\n",
    "    df_hist = compute_histogram(col, nbins=30)\n",
    "\n",
    "    ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "    ax.set_title(f\"Histogram of {col.replace('_',' ').title()}\")\n",
    "    ax.set_xlabel(col.replace('_',' ').title())\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf023e22-310a-46df-b795-2fb5e529ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of clear_percent ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"clear_percent\", nbins=30)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'clear_percent'.title()}\")\n",
    "ax.set_xlabel(\"clear_percent\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6431d186-cf29-4754-9c57-72e78b156936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT (-47.71420246434783 -60.5792815383332)\n"
     ]
    }
   ],
   "source": [
    "from src.tides import find_nearest_coordinate, tide_model as create_tidal_model, datetimes_to_delta\n",
    "from shapely.ops import transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "local_crs = grid_df.estimate_utm_crs()\n",
    "grid_point_local = grid_df.to_crs(local_crs).geometry.iloc[0].centroid\n",
    "transformer = Transformer.from_crs(local_crs, grid_df.crs, always_xy=True)\n",
    "\n",
    "# 2. Write a small wrapper that matches the shapely.ops.transform signature\n",
    "def project(x, y, z=None):\n",
    "    # pyproj returns (x2, y2) or (x2, y2, z2) depending on input\n",
    "    if z is None:\n",
    "        x2, y2 = transformer.transform(x, y)\n",
    "        return x2, y2\n",
    "    else:\n",
    "        x2, y2, z2 = transformer.transform(x, y, z)\n",
    "        return x2, y2, z2\n",
    "\n",
    "# 4. Apply the projection\n",
    "grid_point = transform(project, grid_point_local)\n",
    "\n",
    "print(grid_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c647a54-3fda-43e7-9eb3-440a0e8885f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_model = create_tidal_model(Path(\"/Users/kyledorman/data/tides\"), \"GOT4.10\", \"GOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035f57c-a9bd-4b56-9faf-e60c543657ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlons = np.array([[grid_point.y, grid_point.x]])\n",
    "dove_tides = tide_model.tide_elevations(latlons, times=[sample_df.acquired])[0]\n",
    "sample_df[\"tide_height\"] = dove_tides\n",
    "tides_year = np.load(\"../extracted/tides_2023.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850f294-7d5c-4e03-9ce7-7b1ed2eab528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert\n",
    "# 1. build the analytic signal\n",
    "analytic = hilbert(tides_year)\n",
    "\n",
    "# 2. instantaneous phase in radians (–π → +π)\n",
    "phase_rad = np.angle(analytic)\n",
    "phase_rad = np.mod(phase_rad, 2*np.pi)\n",
    "\n",
    "start = np.datetime64(\"2023-12-01T00:00\")\n",
    "end = np.datetime64(\"2024-12-01T00:00\")\n",
    "minutes = np.arange(start, end, np.timedelta64(1, \"m\"))\n",
    "\n",
    "phase_series = pd.Series(phase_rad, index=pd.to_datetime(minutes))\n",
    "phase_series = phase_series.sort_index()\n",
    "\n",
    "sample_df['phase'] = (\n",
    "    phase_series\n",
    "    .reindex(sample_df['acquired'], method='nearest')\n",
    "    .values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4597ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92651cad-ff5e-4e35-9d3e-d6f906b80575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Inputs ────────────────────────────────────────────────────────────────────\n",
    "# minute_heights       : 1D np.array of per-minute tide heights (floats)\n",
    "# minute_phases_rad    : 1D np.array of per-minute tide phases (radians in [–π, π])\n",
    "# samples_df           : pandas.DataFrame with columns\n",
    "#                          'tide_height' (float)\n",
    "#                          'phase'       (float in radians)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Define common bin edges\n",
    "phase_edges  = np.linspace(0, 2 * np.pi, 37)               # 36 equal bins over [–π, π]\n",
    "height_edges = np.histogram_bin_edges(tides_year, bins=30)\n",
    "\n",
    "# 2) Compute histogram counts for shared y‐limit\n",
    "counts_phase_min,  _ = np.histogram(phase_rad,      bins=phase_edges)\n",
    "counts_phase_samp, _ = np.histogram(sample_df['phase'],    bins=phase_edges)\n",
    "counts_height_min,  _ = np.histogram(tides_year,        bins=height_edges)\n",
    "counts_height_samp, _ = np.histogram(sample_df['tide_height'], bins=height_edges)\n",
    "\n",
    "y_max_minutes = max(\n",
    "    counts_phase_min.max(),\n",
    "    counts_height_min.max(),\n",
    ") * 1.1  # 10% headroom\n",
    "y_max_samp = max(\n",
    "    counts_phase_samp.max(),\n",
    "    counts_height_samp.max(),\n",
    ") * 1.1  # 10% headroom\n",
    "# 3) Plot 2×2 grid of histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Top-left: Phase (minute series)\n",
    "axes[0,0].hist(phase_rad, bins=phase_edges, edgecolor='black')\n",
    "axes[0,0].set_title('Phase Histogram (Minute Series)')\n",
    "axes[0,0].set_xlim(0, 2 * np.pi)\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].set_ylim(0, y_max_minutes)\n",
    "\n",
    "# Top-right: Phase (samples_df)\n",
    "axes[0,1].hist(sample_df['phase'], bins=phase_edges, edgecolor='black')\n",
    "axes[0,1].set_title('Phase Histogram (Samples)')\n",
    "axes[0,1].set_xlim(0, 2 * np.pi)\n",
    "axes[0,1].set_ylim(0, y_max_samp)\n",
    "\n",
    "# Bottom-left: Height (minute series)\n",
    "axes[1,0].hist(tides_year, bins=height_edges, edgecolor='black')\n",
    "axes[1,0].set_title('Height Histogram (Minute Series)')\n",
    "axes[1,0].set_xlim(height_edges[0], height_edges[-1])\n",
    "axes[1,0].set_xlabel('Tide Height')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_ylim(0, y_max_minutes)\n",
    "\n",
    "# Bottom-right: Height (samples_df)\n",
    "axes[1,1].hist(sample_df['tide_height'], bins=height_edges, edgecolor='black')\n",
    "axes[1,1].set_title('Height Histogram (Samples)')\n",
    "axes[1,1].set_xlim(height_edges[0], height_edges[-1])\n",
    "axes[1,1].set_xlabel('Tide Height')\n",
    "axes[1,1].set_ylim(0, y_max_samp)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b82d19-68f8-4397-9c59-f42b1f95283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 2))\n",
    "plt.scatter(y=phase_rad[:10000], x=np.arange(len(phase_rad[:10000])), s=0.1, marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67a292-31f0-4027-b846-387d7f66d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 2))\n",
    "plt.scatter(y=tides_year[:10000], x=np.arange(len(phase_rad[:10000])), s=0.1, marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988606f-edea-41df-be08-b49512e3136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 36               # e.g. 10° bins\n",
    "counts, bin_edges = np.histogram(\n",
    "    phase_rad, bins=num_bins, range=(0, 2*np.pi)\n",
    ")\n",
    "width = bin_edges[1] - bin_edges[0]\n",
    "angles = bin_edges[:-1]     # start angle of each bin\n",
    "\n",
    "# 3) plot on a polar axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='polar')\n",
    "ax.bar(angles, counts, width=width, align='edge')\n",
    "\n",
    "# 4) beautify axes\n",
    "ax.set_theta_zero_location('N')    # 0° at top (high water)\n",
    "ax.set_theta_direction(-1)         # clockwise\n",
    "ax.set_xticks(np.deg2rad([0, 90, 180, 270]))\n",
    "ax.set_xticklabels(['0° (High)', '90°', '180° (Low)', '270°'])\n",
    "# ax.set_title('Tidal Phase Rose Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe407a-5514-4216-995f-b15d934fcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 36               # e.g. 10° bins\n",
    "counts, bin_edges = np.histogram(\n",
    "    sample_df.phase, bins=num_bins, range=(0, 2*np.pi)\n",
    ")\n",
    "width = bin_edges[1] - bin_edges[0]\n",
    "angles = bin_edges[:-1]     # start angle of each bin\n",
    "\n",
    "# 3) plot on a polar axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='polar')\n",
    "ax.bar(angles, counts, width=width, align='edge')\n",
    "\n",
    "# 4) beautify axes\n",
    "ax.set_theta_zero_location('N')    # 0° at top (high water)\n",
    "ax.set_theta_direction(-1)         # clockwise\n",
    "ax.set_xticks(np.deg2rad([0, 90, 180, 270]))\n",
    "ax.set_xticklabels(['0° (High)', '90°', '180° (Low)', '270°'])\n",
    "# ax.set_title('Tidal Phase Rose Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d42cec-3ebd-45a1-b000-347a23129d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.sort_values(by=\"acquired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc073346",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBINS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab88e6-e203-4552-aa96-de0bdaf8405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute 10 equal‐width bins over the full range of all_heights\n",
    "height_edges = np.histogram_bin_edges(tides_year, bins=NBINS)\n",
    "height_edges[-1] += 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b428-c705-4ac9-a89d-c8de4c48c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives integer bins 0–9\n",
    "sample_df['height_bin'] = pd.cut(\n",
    "    sample_df['tide_height'],\n",
    "    bins=height_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "assert not sample_df['height_bin'].isna().any()\n",
    "sample_df['height_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f9795-269b-40cb-a7e5-0f6857866ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBINS equal bins around the circle, bin 0 = [0, 2π/10)\n",
    "delta = 2*np.pi/NBINS\n",
    "sample_df['phase_shift'] = (sample_df['phase'] + delta/2) % (2*np.pi)\n",
    "phase_edges = np.linspace(0, 2*np.pi, NBINS+1)\n",
    "phase_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b534c-321f-4412-b1de-ca8792949d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['phase_bin'] = pd.cut(\n",
    "    sample_df['phase_shift'],\n",
    "    bins=phase_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    "    right=False\n",
    ")\n",
    "assert not sample_df['phase_bin'].isna().any()\n",
    "sample_df['phase_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d176845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phase_shift = (phase_rad + delta/2) % (2*np.pi)\n",
    "minute_phase_bin = pd.cut(\n",
    "    phase_shift,\n",
    "    bins=phase_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    "    right=False\n",
    ")\n",
    "minute_height_bin = pd.cut(\n",
    "    tides_year,\n",
    "    bins=height_edges,\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    "    right=False\n",
    ")\n",
    "start = np.datetime64(\"2023-12-01T00:00\")\n",
    "end = np.datetime64(\"2024-12-01T00:00\")\n",
    "minutes = np.arange(start, end, np.timedelta64(1, \"m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51707c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_by_sliding_window(df, time_col='acquired', N=120):\n",
    "    df2 = df.copy()\n",
    "    df2[time_col] = pd.to_datetime(df2[time_col])\n",
    "    df2 = df2.sort_values(time_col)\n",
    "\n",
    "    keep = []\n",
    "    last_time = None\n",
    "    delta = pd.Timedelta(minutes=N)\n",
    "\n",
    "    for idx, row in df2.iterrows():\n",
    "        t = row[time_col]\n",
    "        if last_time is None or (t - last_time) >= delta:\n",
    "            keep.append(idx)\n",
    "            last_time = t\n",
    "\n",
    "    return df2.loc[keep].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364629dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Sort by time and compute successive differences\n",
    "df_sorted = thin_by_sliding_window(sample_df.sort_values('acquired'), N=120)\n",
    "full_diffs = df_sorted.acquired.diff().dt.total_seconds() / 3600.0\n",
    "\n",
    "clear_sorted = df_sorted[\n",
    "    (df_sorted['clear_percent'] > 80) & \n",
    "    (df_sorted.publishing_stage == \"finalized\") &\n",
    "    (df_sorted.quality_category == \"standard\") &\n",
    "    (df_sorted.has_sr_asset) &\n",
    "    (df_sorted.ground_control)\n",
    "]\n",
    "clear_diffs = clear_sorted.acquired.diff().dt.total_seconds() / 3600.0\n",
    "\n",
    "# 2) Drop the NaN from the first diff\n",
    "full_diffs  = full_diffs.dropna()\n",
    "clear_diffs = clear_diffs.dropna()\n",
    "\n",
    "# 3) Plot histograms side-by-side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "xbins = np.histogram_bin_edges(np.concatenate([full_diffs.to_numpy(), clear_diffs.to_numpy()]), bins=30)\n",
    "\n",
    "# Full dataset\n",
    "ax[0].hist(full_diffs, bins=xbins, edgecolor='black')\n",
    "ax[0].set_title('Acquisition Time Δ (All Samples)')\n",
    "ax[0].set_xlabel('Δ Time (hours)')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "# Clear >80% dataset\n",
    "ax[1].hist(clear_diffs, bins=xbins, edgecolor='black')\n",
    "ax[1].set_title('Acquisition Time Δ (High Quality Samples)')\n",
    "ax[1].set_xlabel('Δ Time (hours)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff769fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Sort by time and compute successive differences\n",
    "df_sorted = thin_by_sliding_window(sample_df.sort_values('acquired'), N=120)\n",
    "full_diffs = df_sorted['tide_height'].diff()\n",
    "\n",
    "clear_sorted = df_sorted[\n",
    "    (df_sorted['clear_percent'] > 80) & \n",
    "    (df_sorted.publishing_stage == \"finalized\") &\n",
    "    (df_sorted.quality_category == \"standard\") &\n",
    "    (df_sorted.has_sr_asset) &\n",
    "    (df_sorted.ground_control)\n",
    "]\n",
    "clear_diffs = clear_sorted['tide_height'].diff()\n",
    "\n",
    "# 2) Drop the NaN from the first diff\n",
    "full_diffs  = full_diffs.dropna()\n",
    "clear_diffs = clear_diffs.dropna()\n",
    "\n",
    "# 3) Plot histograms side-by-side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "xbins = np.histogram_bin_edges(np.concatenate([full_diffs.to_numpy(), clear_diffs.to_numpy()]), bins=30)\n",
    "\n",
    "# Full dataset\n",
    "ax[0].hist(full_diffs, bins=xbins, edgecolor='black')\n",
    "ax[0].set_title('Height Change Histogram (All Samples)')\n",
    "ax[0].set_xlabel('Δ Height (meters)')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "# Clear >80% dataset\n",
    "ax[1].hist(clear_diffs, bins=xbins, edgecolor='black')\n",
    "ax[1].set_title('Height Change Histogram (High Quality Samples)')\n",
    "ax[1].set_xlabel('Δ Height (meters)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebe0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define circular difference wrapped to [–π, π]\n",
    "def circular_diff(phases):\n",
    "    raw = phases.diff()\n",
    "    return ((raw + np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "# 1) Sort by time and compute successive differences\n",
    "df_sorted = thin_by_sliding_window(sample_df.sort_values('acquired'), N=120)\n",
    "full_diffs = circular_diff(df_sorted['phase'])\n",
    "\n",
    "clear_sorted = df_sorted[\n",
    "    (df_sorted['clear_percent'] > 80) & \n",
    "    (df_sorted.publishing_stage == \"finalized\") &\n",
    "    (df_sorted.quality_category == \"standard\") &\n",
    "    (df_sorted.has_sr_asset) &\n",
    "    (df_sorted.ground_control)\n",
    "]\n",
    "clear_diffs = circular_diff(clear_sorted['phase'])\n",
    "\n",
    "# 2) Drop the NaN from the first diff\n",
    "full_diffs  = full_diffs.dropna()\n",
    "clear_diffs = clear_diffs.dropna()\n",
    "\n",
    "# 3) Plot histograms side-by-side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "xbins = np.histogram_bin_edges(np.concatenate([full_diffs.to_numpy(), clear_diffs.to_numpy()]), bins=30)\n",
    "\n",
    "# Full dataset\n",
    "ax[0].hist(full_diffs, bins=xbins, edgecolor='black')\n",
    "ax[0].set_title('Phase Change Histogram (All Samples)')\n",
    "ax[0].set_xlabel('Δ Phase (radians)')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "# Clear >80% dataset\n",
    "ax[1].hist(clear_diffs, bins=xbins, edgecolor='black')\n",
    "ax[1].set_title('Phase Change Histogram (High Quality Samples)')\n",
    "ax[1].set_xlabel('Δ Phase (radians)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e5a85-4888-435a-a30a-ff42b26a8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "high_phase_bin = 0\n",
    "low_phase_bin = NBINS // 2\n",
    "low_height_bin = 0\n",
    "high_height_bin = NBINS - 1\n",
    "\n",
    "# 3) Helper to compute hours between events\n",
    "def compute_hourly_diffs(times):\n",
    "    ints = times.astype('datetime64[s]').astype(np.int64)\n",
    "    return np.diff(np.sort(ints)) / 3600.0\n",
    "\n",
    "run_starts = np.concatenate((\n",
    "    [True],\n",
    "    minute_phase_bin[1:] != minute_phase_bin[:-1]\n",
    "))\n",
    "change_idx = np.nonzero(run_starts)[0]\n",
    "# 2) pull out the first timestamp of each run\n",
    "change_times = minutes[change_idx]\n",
    "change_phase = minute_phase_bin[change_idx]\n",
    "\n",
    "# 4) Extract intervals for each case\n",
    "diffs = {\n",
    "    'year_phase_high':  compute_hourly_diffs(change_times[change_phase == high_phase_bin]),\n",
    "    'year_phase_low':   compute_hourly_diffs(change_times[change_phase == low_phase_bin]),\n",
    "}\n",
    "\n",
    "run_starts = np.concatenate((\n",
    "    [True],\n",
    "    minute_height_bin[1:] != minute_height_bin[:-1]\n",
    "))\n",
    "change_idx = np.nonzero(run_starts)[0]\n",
    "# 2) pull out the first timestamp of each run\n",
    "change_times = minutes[change_idx]\n",
    "change_height = minute_height_bin[change_idx]\n",
    "\n",
    "# usage\n",
    "thinned = thin_by_sliding_window(sample_df, time_col='acquired', N=120)\n",
    "\n",
    "diffs.update({\n",
    "    'year_height_low':  compute_hourly_diffs(change_times[change_height == low_height_bin]),\n",
    "    'year_height_high': compute_hourly_diffs(change_times[change_height == high_height_bin]),\n",
    "    'dove_phase_high':   compute_hourly_diffs(thinned.loc[thinned['phase_bin']==high_phase_bin, 'acquired'].values).clip(0, 250),\n",
    "    'dove_phase_low':    compute_hourly_diffs(thinned.loc[thinned['phase_bin']==low_phase_bin,  'acquired'].values).clip(0, 1000),\n",
    "    'dove_height_low':   compute_hourly_diffs(thinned.loc[thinned['height_bin']==low_height_bin, 'acquired'].values),\n",
    "    'dove_height_high':  compute_hourly_diffs(thinned.loc[thinned['height_bin']==high_height_bin,'acquired'].values).clip(0, 1000),\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(4 * 4, 2 * 4))\n",
    "\n",
    "keys_list = [list(diffs.keys())[:4], list(diffs.keys())[4:]]\n",
    "\n",
    "for i, keys in enumerate(keys_list):\n",
    "    for j, k in enumerate(keys):\n",
    "        vals = diffs[k]\n",
    "        axes[i, j].hist(vals, bins=20)\n",
    "        axes[i, j].set_xlabel('Interval (hours)')\n",
    "        axes[i, j].set_ylabel('Count')\n",
    "        axes[i, j].set_title(k.replace('_',' ').title() + ' Tide Intervals')\n",
    "\n",
    "fig.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.arange(1, 13)\n",
    "\n",
    "# helper to get monthly coverage series\n",
    "def monthly_coverage(df, col):\n",
    "    # nunique bin per month\n",
    "    s = df.groupby(df['acquired'].dt.month)[col].nunique()\n",
    "    # % of total bins\n",
    "    return (s.reindex(months, fill_value=0) / NBINS * 100).values\n",
    "\n",
    "# 1) compute for all rows\n",
    "phase_cov_all  = monthly_coverage(sample_df, 'phase_bin')\n",
    "height_cov_all = monthly_coverage(sample_df, 'height_bin')\n",
    "\n",
    "# 2) compute for clear > 80%\n",
    "df_clear = sample_df[\n",
    "    (sample_df['clear_percent'] > 80) & \n",
    "    (sample_df.publishing_stage == \"finalized\") &\n",
    "    (sample_df.quality_category == \"standard\") &\n",
    "    (sample_df.has_sr_asset) &\n",
    "    (sample_df.ground_control)\n",
    "]\n",
    "phase_cov_clr  = monthly_coverage(df_clear, 'phase_bin')\n",
    "height_cov_clr = monthly_coverage(df_clear, 'height_bin')\n",
    "\n",
    "# 3) plot\n",
    "width = 0.35\n",
    "x = months\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5), sharey=True)\n",
    "\n",
    "# Phase coverage\n",
    "axes[0].bar(x - width/2, phase_cov_all,  width, label='All')\n",
    "axes[0].bar(x + width/2, phase_cov_clr,  width, label='High Quality Samples')\n",
    "axes[0].set_xticks(months)\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Coverage (%)')\n",
    "axes[0].set_title('Monthly Tidal Phase Coverage')\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[0].legend()\n",
    "\n",
    "# Height coverage\n",
    "axes[1].bar(x - width/2, height_cov_all, width, label='All')\n",
    "axes[1].bar(x + width/2, height_cov_clr, width, label='High Quality Samples')\n",
    "axes[1].set_xticks(months)\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Coverage (%)')\n",
    "axes[1].set_title('Monthly Tidal Height Coverage')\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d759f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.arange(1, 13)\n",
    "\n",
    "year_df = pd.DataFrame({\n",
    "    'phase_bin': minute_phase_bin,\n",
    "    'height_bin': minute_height_bin,\n",
    "    'acquired': minutes\n",
    "})\n",
    "\n",
    "# 1) compute for all rows\n",
    "phase_cov_all  = monthly_coverage(year_df, 'phase_bin')\n",
    "height_cov_all = monthly_coverage(year_df, 'height_bin')\n",
    "\n",
    "# 3) plot\n",
    "width = 0.35\n",
    "x = months\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "# Phase coverage\n",
    "axes[0].bar(x - width/2, phase_cov_all,  width, label='All')\n",
    "axes[0].set_xticks(months)\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Coverage (%)')\n",
    "axes[0].set_title('Monthly Tidal Phase Coverage')\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[0].legend()\n",
    "\n",
    "# Height coverage\n",
    "axes[1].bar(x - width/2, height_cov_all, width, label='All')\n",
    "axes[1].set_xticks(months)\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Coverage (%)')\n",
    "axes[1].set_title('Monthly Tidal Height Coverage')\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "months = np.arange(1,13)\n",
    "high_phase_bins  = 0\n",
    "low_phase_bins   = NBINS//2\n",
    "low_height_bin  = 0\n",
    "high_height_bin = NBINS-1\n",
    "\n",
    "# helper to get monthly counts\n",
    "def monthly_counts(df, col, bin_idx):\n",
    "    if isinstance(bin_idx, list):\n",
    "        s = df[df[col].isin(bin_idx)].groupby(df['acquired'].dt.month).size()\n",
    "    else:\n",
    "        s = df[df[col]==bin_idx].groupby(df['acquired'].dt.month).size()\n",
    "    return s.reindex(months, fill_value=0).values\n",
    "\n",
    "# compute counts\n",
    "counts = {\n",
    "    'phase_high_all':  monthly_counts(sample_df,       'phase_bin',  high_phase_bins),\n",
    "    'phase_high_clr':  monthly_counts(df_clear, 'phase_bin',  high_phase_bins),\n",
    "    'phase_low_all':   monthly_counts(sample_df,       'phase_bin',  low_phase_bins),\n",
    "    'phase_low_clr':   monthly_counts(df_clear, 'phase_bin',  low_phase_bins),\n",
    "    'height_high_all': monthly_counts(sample_df,       'height_bin', high_height_bin),\n",
    "    'height_high_clr': monthly_counts(df_clear, 'height_bin', high_height_bin),\n",
    "    'height_low_all':  monthly_counts(sample_df,       'height_bin', low_height_bin),\n",
    "    'height_low_clr':  monthly_counts(df_clear, 'height_bin', low_height_bin),\n",
    "}\n",
    "\n",
    "# plot 2x2\n",
    "fig, axs = plt.subplots(2, 2, figsize=(11,6), sharex=True, sharey=True)\n",
    "width = 0.35\n",
    "x = months\n",
    "\n",
    "# top-left: phase high\n",
    "axs[0,0].bar(x-width/2, counts['phase_high_all'],  width, label='All')\n",
    "axs[0,0].bar(x+width/2, counts['phase_high_clr'],  width, label='High Quality Samples')\n",
    "axs[0,0].set_title('Phase High Tide Count')\n",
    "\n",
    "# top-right: phase low\n",
    "axs[0,1].bar(x-width/2, counts['phase_low_all'],   width, label='All')\n",
    "axs[0,1].bar(x+width/2, counts['phase_low_clr'],   width, label='High Quality Samples')\n",
    "axs[0,1].set_title('Phase Low Tide Count')\n",
    "\n",
    "# bottom-left: height high\n",
    "axs[1,0].bar(x-width/2, counts['height_high_all'], width, label='All')\n",
    "axs[1,0].bar(x+width/2, counts['height_high_clr'], width, label='High Quality Samples')\n",
    "axs[1,0].set_title('Height High Tide Count')\n",
    "\n",
    "# bottom-right: height low\n",
    "axs[1,1].bar(x-width/2, counts['height_low_all'],  width, label='All')\n",
    "axs[1,1].bar(x+width/2, counts['height_low_clr'],  width, label='High Quality Samples')\n",
    "axs[1,1].set_title('Height Low Tide Count')\n",
    "\n",
    "# common formatting\n",
    "for ax in axs.flat:\n",
    "    ax.set_xticks(months)\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "months = np.arange(1,13)\n",
    "high_phase_bins  = 0\n",
    "low_phase_bins   = NBINS//2\n",
    "low_height_bin  = 0\n",
    "high_height_bin = NBINS-1\n",
    "\n",
    "# helper to get monthly counts\n",
    "def monthly_counts(df, col, bin_idx):\n",
    "    if isinstance(bin_idx, list):\n",
    "        s = df[df[col].isin(bin_idx)].groupby(df['acquired'].dt.month).size()\n",
    "    else:\n",
    "        s = df[df[col]==bin_idx].groupby(df['acquired'].dt.month).size()\n",
    "    return s.reindex(months, fill_value=0).values\n",
    "\n",
    "# compute counts\n",
    "counts = {\n",
    "    'phase_high_all':  monthly_counts(year_df,       'phase_bin',  high_phase_bins),\n",
    "    'phase_low_all':   monthly_counts(year_df,       'phase_bin',  low_phase_bins),\n",
    "    'height_high_all': monthly_counts(year_df,       'height_bin', high_height_bin),\n",
    "    'height_low_all':  monthly_counts(year_df,       'height_bin', low_height_bin),\n",
    "}\n",
    "\n",
    "# plot 2x2\n",
    "fig, axs = plt.subplots(2, 2, figsize=(11,6), sharex=True)\n",
    "width = 0.35\n",
    "x = months\n",
    "\n",
    "# top-left: phase high\n",
    "axs[0,0].bar(x-width/2, counts['phase_high_all'],  width, label='All')\n",
    "# axs[0,0].bar(x+width/2, counts['phase_high_clr'],  width, label='High Quality Samples')\n",
    "axs[0,0].set_title('Phase High Tide Count')\n",
    "\n",
    "# top-right: phase low\n",
    "axs[0,1].bar(x-width/2, counts['phase_low_all'],   width, label='All')\n",
    "# axs[0,1].bar(x+width/2, counts['phase_low_clr'],   width, label='High Quality Samples')\n",
    "axs[0,1].set_title('Phase Low Tide Count')\n",
    "\n",
    "# bottom-left: height high\n",
    "axs[1,0].bar(x-width/2, counts['height_high_all'], width, label='All')\n",
    "# axs[1,0].bar(x+width/2, counts['height_high_clr'], width, label='High Quality Samples')\n",
    "axs[1,0].set_title('Height High Tide Count')\n",
    "\n",
    "# bottom-right: height low\n",
    "axs[1,1].bar(x-width/2, counts['height_low_all'],  width, label='All')\n",
    "# axs[1,1].bar(x+width/2, counts['height_low_clr'],  width, label='High Quality Samples')\n",
    "axs[1,1].set_title('Height Low Tide Count')\n",
    "\n",
    "# common formatting\n",
    "for ax in axs.flat:\n",
    "    ax.set_xticks(months)\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Rename your thinned DF to df_thin (or adjust the name below)\n",
    "df_thin = sample_df.copy() # thin_by_sliding_window(sample_df, time_col='acquired', N=60)\n",
    "df_thin = df_thin.sort_values('acquired')\n",
    "\n",
    "# 2) Prepare\n",
    "bin_count = NBINS\n",
    "bins = np.arange(bin_count)\n",
    "matrix = np.full((bin_count, bin_count), np.nan)\n",
    "percentile = 50\n",
    "\n",
    "# 3) For each start‐bin i and target‐bin j, find the 90th-percentile Δt\n",
    "for i in bins:\n",
    "    # all times when we saw phase = i\n",
    "    times_i = df_thin.loc[df_thin['phase_bin'] == i, 'acquired']\n",
    "    # wrap into a frame for merging\n",
    "    df_i = pd.DataFrame({'time_i': times_i.sort_values().values})\n",
    "\n",
    "    for j in bins:\n",
    "        # all times when we saw phase = j\n",
    "        times_j = df_thin.loc[df_thin['phase_bin'] == j, 'acquired']\n",
    "        df_j = pd.DataFrame({'time_j': times_j.sort_values().values})\n",
    "\n",
    "        # for each i, find the next j at or after it\n",
    "        merged = pd.merge_asof(\n",
    "            df_i, \n",
    "            df_j, \n",
    "            left_on='time_i', \n",
    "            right_on='time_j', \n",
    "            direction='forward'\n",
    "        )\n",
    "\n",
    "        # compute Δt in hours\n",
    "        deltas = (merged['time_j'] - merged['time_i']).dt.total_seconds() / 3600.0 / 24.0\n",
    "        deltas = deltas.dropna()\n",
    "        if len(deltas):\n",
    "            matrix[i, j] = np.percentile(deltas, percentile)\n",
    "\n",
    "# 4) Plot heatmap of the 90th percentile Δt\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(matrix, origin='lower', aspect='auto', cmap='viridis')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xticks(bins)\n",
    "ax.set_yticks(bins)\n",
    "ax.set_xlabel('Target phase bin (j)')\n",
    "ax.set_ylabel('Start phase bin (i)')\n",
    "ax.set_title('90th Percentile Time (days) Between Phase Bins')\n",
    "\n",
    "# annotate each cell\n",
    "for i in bins:\n",
    "    for j in bins:\n",
    "        val = matrix[i, j]\n",
    "        if not np.isnan(val):\n",
    "            ax.text(j, i, f\"{val:.1f}\", ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "# colorbar\n",
    "cbar = fig.colorbar(im, ax=ax, label='Days (90th percentile)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426fda0-1e19-419b-a284-6b88fcb02e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base map centered on the calculated location\n",
    "centroid = grid_df.geometry.iloc[0].centroid\n",
    "base_map = folium.Map(location=[centroid.y, centroid.x], zoom_start=2, width=1000, height=800)\n",
    "\n",
    "for geo in grid_df.geometry:\n",
    "    folium.GeoJson(\n",
    "        geo,\n",
    "    ).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thin = sample_df.copy() # thin_by_sliding_window(sample_df, time_col='acquired', N=60)\n",
    "df_thin = df_thin.sort_values('acquired')\n",
    "\n",
    "# 2) Prepare\n",
    "bin_count = NBINS\n",
    "bins = np.arange(bin_count)\n",
    "matrix = np.full((bin_count, bin_count), np.nan)\n",
    "percentile = 90\n",
    "\n",
    "# 3) For each start‐bin i and target‐bin j, find the 90th-percentile Δt\n",
    "for i in bins:\n",
    "    # all times when we saw phase = i\n",
    "    times_i = df_thin.loc[df_thin['height_bin'] == i, 'acquired']\n",
    "    # wrap into a frame for merging\n",
    "    df_i = pd.DataFrame({'time_i': times_i.sort_values().values})\n",
    "\n",
    "    for j in bins:\n",
    "        # all times when we saw phase = j\n",
    "        times_j = df_thin.loc[df_thin['height_bin'] == j, 'acquired']\n",
    "        df_j = pd.DataFrame({'time_j': times_j.sort_values().values})\n",
    "\n",
    "        # for each i, find the next j at or after it\n",
    "        merged = pd.merge_asof(\n",
    "            df_i, \n",
    "            df_j, \n",
    "            left_on='time_i', \n",
    "            right_on='time_j', \n",
    "            direction='forward'\n",
    "        )\n",
    "\n",
    "        # compute Δt in hours\n",
    "        deltas = (merged['time_j'] - merged['time_i']).dt.total_seconds() / 3600.0 / 24.0\n",
    "        deltas = deltas.dropna()\n",
    "        if len(deltas):\n",
    "            matrix[i, j] = np.percentile(deltas, percentile)\n",
    "\n",
    "# 4) Plot heatmap of the 90th percentile Δt\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(matrix, origin='lower', aspect='auto', cmap='viridis')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xticks(bins)\n",
    "ax.set_yticks(bins)\n",
    "ax.set_xlabel('Target height bin (j)')\n",
    "ax.set_ylabel('Start height bin (i)')\n",
    "ax.set_title('90th Percentile Time (days) Between Height Bins')\n",
    "\n",
    "# annotate each cell\n",
    "for i in bins:\n",
    "    for j in bins:\n",
    "        val = matrix[i, j]\n",
    "        if not np.isnan(val):\n",
    "            ax.text(j, i, f\"{val:.1f}\", ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "# colorbar\n",
    "cbar = fig.colorbar(im, ax=ax, label='Days (90th percentile)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312d254-fd91-4bd3-892a-eca212dff272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tide_df.columns:\n",
    "    tide_df.loc[tide_df[col].isna(), col] = 365.0\n",
    "tide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7f926-8a42-4930-8782-93be93930e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 1. polygons → centroids and join metrics\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "gdf_pts = (\n",
    "    grid_df.to_crs(all_grids_df.crs)        # CRS match\n",
    "           .assign(geometry=lambda d: d.geometry.centroid)\n",
    "           .merge(tide_df, on=\"cell_id\")\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 2. axes layout: rows = sensors, cols = metrics\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "sensors       = [\"planet\", \"sentinel\", \"landsat\"]\n",
    "base_metrics  = [\"count\"]\n",
    "metrics       = [f\"{lvl}_{m}\" for m in base_metrics for lvl in (\"low\", \"high\")]\n",
    "\n",
    "nrows, ncols  = len(sensors), len(metrics)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * 5, nrows * 2),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 3.  loop over columns (metrics) to set a shared scale per column\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "cmap = \"viridis\"\n",
    "\n",
    "for c, metric in enumerate(metrics):\n",
    "    # shared vmin/vmax across sensors for this metric\n",
    "    col_values = [f\"{sat}_{metric}\" for sat in sensors]\n",
    "    vmin = gdf_pts[col_values].min().min()\n",
    "    vmax = gdf_pts[col_values].max().max()\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    for r, sensor in enumerate(sensors):\n",
    "        ax      = axes[r, c]\n",
    "        colname = f\"{sensor}_{metric}\"\n",
    "\n",
    "        gdf_pts.plot(\n",
    "            column     = colname,\n",
    "            ax         = ax,\n",
    "            cmap       = cmap,\n",
    "            norm       = norm,\n",
    "            marker     = \"o\",\n",
    "            markersize = 1,\n",
    "            linewidth  = 0,\n",
    "            legend     = False,\n",
    "        )\n",
    "\n",
    "        # titles: top row gets metric title; first column gets sensor label\n",
    "        ax.set_title(f\"{sensor.title()} {metric.replace('_', ' ').title()}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # add ONE colour‑bar for the whole column\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap);  sm.set_array([])\n",
    "    cax = fig.colorbar(sm, ax=axes[0, c], shrink=0.6, pad=0.02, location=\"right\")\n",
    "    cax.ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "\n",
    "plt.savefig(\"/Users/kyledorman/Desktop/tide_count.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f937149-6741-4b26-910d-946c1a673a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 1. polygons → centroids and join metrics\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "gdf_pts = (\n",
    "    grid_df.to_crs(all_grids_df.crs)        # CRS match\n",
    "           .assign(geometry=lambda d: d.geometry.centroid)\n",
    "           .merge(tide_df, on=\"cell_id\")\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 2. axes layout: rows = sensors, cols = metrics\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "sensors       = [\"planet\", \"sentinel\", \"landsat\"]\n",
    "base_metrics  = [\"days_between_p95\"]\n",
    "metrics       = [f\"{lvl}_{m}\" for m in base_metrics for lvl in (\"low\", \"high\")]\n",
    "\n",
    "nrows, ncols  = len(sensors), len(metrics)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * 5, nrows * 2),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 3.  loop over columns (metrics) to set a shared scale per column\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "cmap = \"viridis\"\n",
    "\n",
    "for c, metric in enumerate(metrics):\n",
    "    # shared vmin/vmax across sensors for this metric\n",
    "    col_values = [f\"{sat}_{metric}\" for sat in sensors]\n",
    "    vmin = 0 # gdf_pts[col_values].min().min()\n",
    "    vmax = gdf_pts[col_values].max().max()\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    for r, sensor in enumerate(sensors):\n",
    "        ax      = axes[r, c]\n",
    "        colname = f\"{sensor}_{metric}\"\n",
    "\n",
    "        gdf_pts.plot(\n",
    "            column     = colname,\n",
    "            ax         = ax,\n",
    "            cmap       = cmap,\n",
    "            norm       = norm,\n",
    "            marker     = \"o\",\n",
    "            markersize = 1,\n",
    "            linewidth  = 0,\n",
    "            legend     = False,\n",
    "        )\n",
    "\n",
    "        # titles: top row gets metric title; first column gets sensor label\n",
    "        ax.set_title(f\"{sensor.title()} {metric.replace('_', ' ').title()}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # add ONE colour‑bar for the whole column\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap);  sm.set_array([])\n",
    "    cax = fig.colorbar(sm, ax=axes[0, c], shrink=0.6, pad=0.02, location=\"right\")\n",
    "    cax.ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "\n",
    "plt.savefig(\"/Users/kyledorman/Desktop/tide_days_between_p95.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116fe6a-1fff-4974-bb11-5bf1a89c5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors       = [\"planet\", \"sentinel\", \"landsat\"]\n",
    "base_metrics  = [\"count\"]\n",
    "metrics       = [f\"{lvl}_{m}\" for m in base_metrics for lvl in (\"low\", \"high\")]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(metric, \"% No observations\")\n",
    "    for sensor in sensors:\n",
    "        print(sensor, round(100 * (tide_df[f'{sensor}_{metric}'] == 0).sum() / len(tide_df), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b56ff9-7a0f-4796-9527-4f9999714dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors       = [\"planet\", \"sentinel\", \"landsat\"]\n",
    "base_metrics  = [\"days_between_p95\"]\n",
    "metrics       = [f\"{lvl}_{m}\" for m in base_metrics for lvl in (\"low\", \"high\")]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(metric, \"% > 100 days\")\n",
    "    for sensor in sensors:\n",
    "        print(sensor, round(100 * (tide_df[f'{sensor}_{metric}'] > 100).sum() / len(tide_df), 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
