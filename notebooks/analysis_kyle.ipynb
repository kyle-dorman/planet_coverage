{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997513c2-5c95-4bb9-944e-c1d7379903d8",
   "metadata": {},
   "source": [
    "# DuckDB + Parquet Data Exploration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8991d-9b51-4869-8aa1-7199bd7cc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colors, ticker\n",
    "from typing import Optional, Tuple\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import folium\n",
    "import matplotlib.dates as mdates\n",
    "from random import shuffle\n",
    "\n",
    "from src.gen_points_map import compute_step, make_equal_area_hex_grid, make_equal_area_grid\n",
    "from src.geo_util import assign_intersection_id\n",
    "from src.plotting.util import plot_gdf_column\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # hide every warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8fff9-14d0-46f0-86a6-826aa299b5f8",
   "metadata": {},
   "source": [
    "# --- Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7d488-22fa-4e4f-8f03-75b024e60d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"/Users/kyledorman/data/planet_coverage/ca_only/\")  # <-- update this\n",
    "\n",
    "# Example path patterns\n",
    "f_pattern = \"*/coastal_results/*/*/*/coastal_points.parquet\"\n",
    "all_files_pattern = str(BASE / f_pattern)\n",
    "\n",
    "# Combined list used later when we search individual files\n",
    "all_parquets = list(BASE.glob(f_pattern))\n",
    "\n",
    "IDX = 1\n",
    "hex_id = f\"{IDX:06x}\"  # unique 6‑digit hex, e.g. '0f1a2b'\n",
    "d1, d2, d3 = hex_id[:2], hex_id[2:4], hex_id[4:6]\n",
    "GRID_PATH = BASE / \"dove\" / \"coastal_results\" / d1 / d2 / d3\n",
    "FILE = GRID_PATH / \"coastal_points.parquet\"\n",
    "\n",
    "assert FILE.exists()\n",
    "\n",
    "len(all_parquets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f78e9-07c5-4468-98d7-3667c1958238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_crs = \"EPSG:4326\"\n",
    "robinson_crs = \"ESRI:54030\"\n",
    "sinus_crs = \"ESRI:54008\"\n",
    "\n",
    "ca_ocean = gpd.read_file(BASE / \"la.geojson\")\n",
    "query_df = gpd.read_file(BASE / \"ocean_grids.gpkg\")\n",
    "grids_df = gpd.read_file(BASE / \"coastal_grids.gpkg\").rename(columns={\"cell_id\": \"grid_id\"})\n",
    "heuristics_df = pd.read_csv(BASE / \"simulated_tidal_coverage_heuristics.csv\").set_index(\"cell_id\")\n",
    "\n",
    "cell_size_m = compute_step(0.5)\n",
    "_, hex_grid = make_equal_area_hex_grid(cell_size_m, robinson_crs)\n",
    "hex_grid = hex_grid.rename(columns={\"cell_id\": \"hex_id\"}).to_crs(display_crs)\n",
    "\n",
    "cell_size_m = compute_step(2.0)\n",
    "_, big_grid = make_equal_area_grid(cell_size_m, robinson_crs)\n",
    "big_grid = big_grid.rename(columns={\"cell_id\": \"square_id\"}).to_crs(display_crs)\n",
    "\n",
    "# Assign hex_id to query_df and grid_df\n",
    "grids_df = assign_intersection_id(grids_df, hex_grid, \"grid_id\", \"hex_id\", sinus_crs)\n",
    "query_df = assign_intersection_id(query_df, hex_grid, \"cell_id\", \"hex_id\", sinus_crs)\n",
    "\n",
    "# Assign cell_id to grid_df\n",
    "grids_df = assign_intersection_id(grids_df, query_df, \"grid_id\", \"cell_id\", sinus_crs)\n",
    "\n",
    "# Assign square_id to grids_df\n",
    "grids_df = assign_intersection_id(grids_df, big_grid, \"grid_id\", \"square_id\", sinus_crs)\n",
    "\n",
    "# Add tidal information to grids_df and query_df\n",
    "grids_df = grids_df.set_index(\"cell_id\").join(heuristics_df, how='left').reset_index()\n",
    "query_df = query_df.set_index(\"cell_id\").join(heuristics_df, how='left').reset_index()\n",
    "\n",
    "# Set plot crs\n",
    "query_df = query_df.to_crs(display_crs)\n",
    "grids_df = grids_df.to_crs(display_crs)\n",
    "big_grid = big_grid.to_crs(display_crs)\n",
    "\n",
    "# Set indexes\n",
    "query_df = query_df.set_index(\"cell_id\")\n",
    "grids_df = grids_df.set_index(\"grid_id\")\n",
    "hex_grid = hex_grid.set_index(\"hex_id\")\n",
    "big_grid = big_grid.set_index(\"square_id\")\n",
    "\n",
    "# Filter grids to CA region\n",
    "query_ca = query_df[query_df.geometry.intersects(ca_ocean.union_all())]\n",
    "grids_ca = grids_df[grids_df.geometry.intersects(query_ca.union_all())]\n",
    "hex_grid_ca = hex_grid[hex_grid.geometry.intersects(query_ca.union_all())]\n",
    "big_grid_ca = big_grid[big_grid.geometry.intersects(query_ca.union_all())]\n",
    "\n",
    "len(grids_ca), len(query_ca), len(hex_grid_ca), len(big_grid_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480c470-81a9-46ad-8025-1c48449dfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = ca_ocean.geometry[0].centroid\n",
    "base_map = folium.Map(location=[centroid.y, centroid.x], zoom_start=5, width=1000, height=800)\n",
    "\n",
    "for idx, geo in enumerate(ca_ocean.geometry):\n",
    "    folium.GeoJson(\n",
    "        geo,\n",
    "        name=str(idx),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"white\",\n",
    "            \"weight\": 4,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "for gid, row in query_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(gid),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"blue\",\n",
    "            \"weight\": 2,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "for gid, row in grids_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(gid),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"green\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "for gid, row in hex_grid_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(gid),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"yellow\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "for gid, row in big_grid_ca.iterrows():\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        popup=str(gid),\n",
    "        style_function=lambda feature: {\n",
    "            \"color\": \"red\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    ).add_to(base_map)\n",
    "\n",
    "# Display the map\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcdabf3-5ac6-4ff3-98b2-267a3460e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/kyledorman/data/planet_coverage/figs/ca_only/la_grids.png\"\n",
    "pad_fraction = 0.05\n",
    "\n",
    "fig = plt.figure(figsize=(11, 6))\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "\n",
    "# Compute extent from data bounds (EPSG:4326) and add a small margin\n",
    "xmin, ymin, xmax, ymax = hex_grid_ca.total_bounds\n",
    "dx, dy = xmax - xmin, ymax - ymin\n",
    "if dx == 0 or dy == 0:        # degenerate case (single point / line)\n",
    "    dx = dy = max(dx, dy) or 1.0  # give it 1° span to avoid zero-width\n",
    "pad_x = dx * pad_fraction\n",
    "pad_y = dy * pad_fraction\n",
    "ax.set_extent([xmin - pad_x, xmax + pad_x, ymin - pad_y, ymax + pad_y], crs=ccrs.PlateCarree())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Plot data\n",
    "# ------------------------------------------------------------------\n",
    "hex_grid_ca.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    edgecolor=\"yellow\",\n",
    "    linewidth=1.0,\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "query_ca.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    edgecolor=\"blue\",\n",
    "    linewidth=1.0,\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "grids_ca.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    edgecolor=\"green\",\n",
    "    linewidth=0.5,\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "big_grid_ca.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    edgecolor=\"red\",\n",
    "    linewidth=1.0,\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "\n",
    "ax.coastlines(resolution=\"110m\", linewidth=0.3)\n",
    "ax.gridlines(draw_labels=False, linewidth=0.2)\n",
    "ax.stock_img()\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_path is not None:\n",
    "    plt.savefig(save_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3680225-407a-4650-a829-6ba8dcb3c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = big_grid.loc[grids_df[grids_df.square_id >= 0].square_id.unique()][[\"geometry\"]].copy()\n",
    "\n",
    "ids = list(range(len(gdf)))\n",
    "shuffle(ids)\n",
    "gdf[\"id\"] = ids\n",
    "\n",
    "n_ids  = gdf[\"id\"].nunique()\n",
    "base_cmap = plt.get_cmap(\"tab20\", n_ids)  # up to 20 unique colours\n",
    "cmap      = colors.ListedColormap(base_cmap(range(n_ids)))\n",
    "norm      = colors.BoundaryNorm(range(n_ids + 1), n_ids)\n",
    "\n",
    "# Pick any Cartopy projection\n",
    "proj = ccrs.Robinson()           # or ccrs.Mollweide(), ccrs.Robinson(), …\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax  = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "\n",
    "# Re-project your data on the fly with `transform`\n",
    "gdf.plot(\n",
    "    column=\"id\",\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    linewidth=0.15,\n",
    "    edgecolor=\"black\",\n",
    "    transform=ccrs.PlateCarree(),   # <- incoming lon/lat coords\n",
    ")\n",
    "\n",
    "plt.title(\"2 degree Square Grids\", pad=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/kyledorman/data/planet_coverage/figs/displays/degree_2_square.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3229ad3-7403-4d47-ae45-107d5a227d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = hex_grid.loc[grids_df[grids_df.hex_id >= 0].hex_id.unique()][[\"geometry\"]].copy()\n",
    "\n",
    "ids = list(range(len(gdf)))\n",
    "shuffle(ids)\n",
    "gdf[\"id\"] = ids\n",
    "\n",
    "n_ids  = gdf[\"id\"].nunique()\n",
    "base_cmap = plt.get_cmap(\"tab20\", n_ids)  # up to 20 unique colours\n",
    "cmap      = colors.ListedColormap(base_cmap(range(n_ids)))\n",
    "norm      = colors.BoundaryNorm(range(n_ids + 1), n_ids)\n",
    "\n",
    "# Pick any Cartopy projection\n",
    "proj = ccrs.Robinson()           # or ccrs.Mollweide(), ccrs.Robinson(), …\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax  = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "\n",
    "# Re-project your data on the fly with `transform`\n",
    "gdf.plot(\n",
    "    column=\"id\",\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    linewidth=0.15,\n",
    "    edgecolor=\"black\",\n",
    "    transform=ccrs.PlateCarree(),   # <- incoming lon/lat coords\n",
    ")\n",
    "ax.stock_img()\n",
    "plt.title(\"Query Grids\", pad=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/kyledorman/data/planet_coverage/figs/displays/query_grids.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bb17a-f54d-4e19-8dfe-5e2667c51ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"/Users/kyledorman/data/planet_coverage/shorelines/antarctica.geojson\")\n",
    "# gdf = hex_grid.loc[grids_df[grids_df.hex_id >= 0].hex_id.unique()][[\"geometry\"]].copy()\n",
    "\n",
    "ids = list(range(len(gdf)))\n",
    "shuffle(ids)\n",
    "gdf[\"id\"] = ids\n",
    "\n",
    "n_ids  = gdf[\"id\"].nunique()\n",
    "base_cmap = plt.get_cmap(\"tab20\", n_ids)  # up to 20 unique colours\n",
    "cmap      = colors.ListedColormap(base_cmap(range(n_ids)))\n",
    "norm      = colors.BoundaryNorm(range(n_ids + 1), n_ids)\n",
    "\n",
    "# Pick any Cartopy projection\n",
    "proj = ccrs.Robinson()           # or ccrs.Mollweide(), ccrs.Robinson(), …\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax  = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "\n",
    "# Re-project your data on the fly with `transform`\n",
    "gdf.plot(\n",
    "    column=\"id\",\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    linewidth=0.15,\n",
    "    edgecolor=\"black\",\n",
    "    transform=ccrs.PlateCarree(),   # <- incoming lon/lat coords\n",
    ")\n",
    "ax.stock_img()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929171dd-9ced-4508-b24a-cf1c6c1b3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect to DuckDB ---\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7262dee-6b6f-4fa2-ad49-d84fc7b20173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for all files\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_all AS\n",
    "    SELECT * FROM read_parquet('{all_files_pattern}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdecbcf-919b-4c11-93b3-03dd314cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for a single file for faster iteration\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_one AS\n",
    "    SELECT * FROM '{FILE}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07135270-ac2b-4a82-8477-d26dc4c18fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schema Inspection ---\n",
    "print(\"Schema of samples_one:\")\n",
    "df = con.execute(\"DESCRIBE samples_one\").fetchdf()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b97d49-1f5c-4497-8676-84d45d412eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NULL Check ---\n",
    "print(\"Checking for NULL values:\")\n",
    "df_nulls = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN id IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
    "        SUM(CASE WHEN acquired IS NULL THEN 1 ELSE 0 END) AS null_acquired,\n",
    "        SUM(CASE WHEN item_type IS NULL THEN 1 ELSE 0 END) AS null_item_type,\n",
    "        SUM(CASE WHEN satellite_id IS NULL THEN 1 ELSE 0 END) AS null_satellite_id,\n",
    "        SUM(CASE WHEN instrument IS NULL THEN 1 ELSE 0 END) AS null_instrument,\n",
    "\n",
    "        SUM(CASE WHEN cell_id IS NULL THEN 1 ELSE 0 END) AS null_cell_id,\n",
    "        SUM(CASE WHEN grid_id IS NULL THEN 1 ELSE 0 END) AS null_grid_id,\n",
    "        \n",
    "        SUM(CASE WHEN has_8_channel IS NULL THEN 1 ELSE 0 END) AS null_has_8_channel,\n",
    "        SUM(CASE WHEN has_sr_asset IS NULL THEN 1 ELSE 0 END) AS null_has_sr_asset,\n",
    "        SUM(CASE WHEN clear_percent IS NULL THEN 1 ELSE 0 END) AS null_clear_percent,\n",
    "        SUM(CASE WHEN quality_category IS NULL THEN 1 ELSE 0 END) AS null_quality_category,\n",
    "        SUM(CASE WHEN ground_control IS NULL THEN 1 ELSE 0 END) AS null_ground_control,\n",
    "        SUM(CASE WHEN publishing_stage IS NULL THEN 1 ELSE 0 END) AS null_publishing_stage,\n",
    "        \n",
    "        SUM(CASE WHEN satellite_azimuth IS NULL THEN 1 ELSE 0 END) AS null_satellite_azimuth,\n",
    "        SUM(CASE WHEN sun_azimuth IS NULL THEN 1 ELSE 0 END) AS null_sun_azimuth,\n",
    "        SUM(CASE WHEN sun_elevation IS NULL THEN 1 ELSE 0 END) AS null_sun_elevation,\n",
    "        SUM(CASE WHEN view_angle IS NULL THEN 1 ELSE 0 END) AS null_view_angle,\n",
    "        \n",
    "        SUM(CASE WHEN tide_height IS NULL THEN 1 ELSE 0 END) AS null_tide_height,\n",
    "        SUM(CASE WHEN has_tide_data IS NULL THEN 1 ELSE 0 END) AS null_has_tide_data,\n",
    "        SUM(CASE WHEN tide_height_bin IS NULL THEN 1 ELSE 0 END) AS null_tide_height_bin,\n",
    "        SUM(CASE WHEN coverage_pct IS NULL THEN 1 ELSE 0 END) AS null_coverage_pct,\n",
    "        SUM(CASE WHEN intersects_grid_centroid IS NULL THEN 1 ELSE 0 END) AS null_intersects_grid_centroid,\n",
    "\n",
    "        SUM(CASE WHEN geometry_wkb IS NULL THEN 1 ELSE 0 END) AS null_geometry_wkb,\n",
    "    FROM samples_one\n",
    "\"\"\").fetchdf()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890dfc09-9521-4213-a778-f0359ef11f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['item_type', 'instrument', 'has_8_channel ', 'has_sr_asset', 'quality_category', 'ground_control', 'publishing_stage']\n",
    "for col in cols:\n",
    "    df = con.execute(f\"SELECT DISTINCT {col} from samples_all\").fetchdf()\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19424005-c171-4b68-ac72-e4031acfd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preview Data ---\n",
    "df_preview = con.execute(\"SELECT * FROM samples_one LIMIT 5\").fetchdf()\n",
    "df_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74743f6e-154a-4279-90bc-395e27edaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter By Time ---\n",
    "df_2024 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM samples_one\n",
    "    WHERE acquired >= '2024-01-01' AND acquired < '2025-01-01'\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "df_2024.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52eef1-2da7-4444-ab8d-e4c1dbb2a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        grid_id, \n",
    "        cell_id,\n",
    "        MIN(acquired) as first_sample,\n",
    "        MAX(acquired) as last_sample\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id, cell_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "print(df_dates.first_sample.min(), df_dates.first_sample.max())\n",
    "print(df_dates.last_sample.min(), df_dates.last_sample.max())\n",
    "print(len(df_dates), len(grids_df))\n",
    "print(len(df_dates.cell_id.unique()), len(query_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5c8f-5dbb-4de2-90fd-6f377556bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "plot_gdf_column(geo_plot, \"sample_count\", title=\"Sample Count PSScene\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118ada5-0a9d-4d6b-a0a1-4da03463fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "df = pd.DataFrame(geo_plot.groupby(\"hex_id\")[\"sample_count\"].sum())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"sample_count\", title=\"Sample Count PSScene Hex\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdec9ac-6a68-4ec2-94c5-6ae83513fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grids_df.groupby(\"hex_id\")[\"dist_km\"].median())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"dist_km\", title=\"dist_km\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a3de4-7d51-476f-bceb-2dd906eb2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    AND coverage_pct > 0.5\n",
    "    AND publishing_stage = 'finalized'\n",
    "    AND quality_category = 'standard'\n",
    "    AND has_sr_asset\n",
    "    AND ground_control\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "df = pd.DataFrame(geo_plot.groupby(\"hex_id\")[\"sample_count\"].sum())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"sample_count\", title=\"High Quality Sample Count\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63125f-cf35-46fa-8240-f3684d73c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id, SUM(coverage_pct > 0.5)::DOUBLE AS coverage_count,  COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_coverage = grids_ca.join(df, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% Greater than 50% coverage\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% Greater than 50% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23e987-12c0-43f2-928a-60dcf8dda32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE as coverage_count,\n",
    "           COUNT(*) AS sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_coverage = grids_ca.join(df_pct, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% Intersects Grid Center\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% Intersects Grid Center\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c2552-ed47-4270-b1bd-e68248d157b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE  / SUM(coverage_pct > 0.5)::DOUBLE AS frac_coverage\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_pct = grids_ca.join(df_pct, how=\"left\").fillna({\"frac_coverage\": 0.0})\n",
    "\n",
    "plot_gdf_column(geo_pct, \"frac_coverage\", title=\"Ration grid center vs 50% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46113e-82c6-49df-8c4d-23a5d39ae83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE  / SUM(coverage_pct > 0.75)::DOUBLE AS frac_coverage\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_pct = grids_ca.join(df_pct, how=\"left\").fillna({\"frac_coverage\": 0.0})\n",
    "\n",
    "plot_gdf_column(geo_pct, \"frac_coverage\", title=\"Ration grid center vs 75% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eff73-4a18-4e0c-9385-024d07d04eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cov = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        grid_id,\n",
    "        COUNT(*)                                                  AS sample_count,\n",
    "        SUM(CASE WHEN coverage_pct > 0.5 THEN 1 ELSE 0 END)      AS coverage_count,\n",
    "    FROM samples_all\n",
    "    WHERE item_type        = 'PSScene'\n",
    "      AND publishing_stage = 'finalized'\n",
    "      AND quality_category = 'standard'\n",
    "      AND has_sr_asset\n",
    "      AND ground_control\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "# join with your coastal grid GeoDataFrame\n",
    "geo_coverage = grids_ca.join(df_cov, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% of high quality captures with >50 % area\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% of high quality captures with >50 % area\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497b136-bbf1-4abf-b565-2c9f10eaa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram Per Day Counts (w/Publish Stage) ---- #\n",
    "\n",
    "# 1. Pull per-day counts broken out by stage\n",
    "df_stage = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        date_trunc('day', acquired) AS day,\n",
    "        publishing_stage,\n",
    "        COUNT(DISTINCT id) AS cnt\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY day, publishing_stage\n",
    "    ORDER BY day\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# 2. Normalize day column and pivot so each stage is its own column\n",
    "df_stage['day'] = pd.to_datetime(df_stage['day']).dt.date\n",
    "df_pivot = (\n",
    "    df_stage\n",
    "    .pivot(index='day', columns='publishing_stage', values='cnt')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 3. Ensure a consistent stack order\n",
    "stages = ['preview', 'finalized', 'standard']\n",
    "df_pivot = df_pivot.reindex(columns=stages, fill_value=0)\n",
    "\n",
    "# 4. Plot stacked bars\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "bottom = np.zeros(len(df_pivot))\n",
    "\n",
    "for stage in stages:\n",
    "    ax.bar(\n",
    "        df_pivot.index.astype(str),\n",
    "        df_pivot[stage],\n",
    "        bottom=bottom,\n",
    "        label=stage\n",
    "    )\n",
    "    bottom += df_pivot[stage].values\n",
    "\n",
    "ax.set_xticklabels(df_pivot.index.astype(str), rotation=45, ha='right')\n",
    "ax.set_title(\"Sample Count per Day by Publishing Stage\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"Sample Count\")\n",
    "ax.legend(title=\"Publishing Stage\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d116df9-8fe2-4519-8488-4cdabc72e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minmax(column: str) -> pd.DataFrame:\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "        MIN({column}) AS minv,\n",
    "        MAX({column}) AS maxv\n",
    "        FROM samples_all\n",
    "        WHERE item_type = 'PSScene'\n",
    "    \"\"\"\n",
    "    return con.execute(sql).fetchdf()\n",
    "\n",
    "def compute_histogram(column: str, nbins: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs DuckDB's histogram() table function on `column` in samples_all (filtered to PSScene)\n",
    "    and returns a DataFrame with columns: bin_upper, frequency.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        WITH bounds AS (\n",
    "          SELECT\n",
    "            MIN({column}) AS mn,\n",
    "            MAX({column}) AS mx\n",
    "          FROM samples_all\n",
    "          WHERE item_type = 'PSScene'\n",
    "        )\n",
    "        SELECT\n",
    "          -- histogram() returns a MAP<upper_boundary, count>\n",
    "          histogram(\n",
    "            {column},\n",
    "            equi_width_bins(bounds.mn::DOUBLE, bounds.mx::DOUBLE, {nbins}::BIGINT, True)\n",
    "          ) AS hist_map\n",
    "        FROM samples_all\n",
    "        CROSS JOIN bounds\n",
    "        WHERE item_type = 'PSScene';\n",
    "    \"\"\"\n",
    "    hist_map = con.execute(sql).fetchdf().iloc[0][\"hist_map\"]\n",
    "\n",
    "    \n",
    "    # Unpack into a two-column DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'bin_upper': list(hist_map.keys()),\n",
    "        'count':     list(hist_map.values())\n",
    "    })\n",
    "    df = df.sort_values('bin_upper').reset_index(drop=True)\n",
    "    uppers = df['bin_upper'].tolist()\n",
    "    bin_size = uppers[1] - uppers[0]\n",
    "    # Compute lower edge from previous upper\n",
    "    lowest = uppers[0] - bin_size\n",
    "    lowers = [lowest] + uppers[:-1]\n",
    "    df[\"bin_lower\"] = pd.Series(lowers)\n",
    "    df[\"centers\"] = (df[\"bin_lower\"] + df['bin_upper']) / 2\n",
    "    df[\"widths\"]  = df['bin_upper'] - df[\"bin_lower\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a1c51-6cc6-4b48-84ff-208eaa737f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 2×2 grid of histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# 2. Plotting all four angle columns\n",
    "for ax, col in zip(axes, [\"satellite_azimuth\", \"sun_azimuth\", \"sun_elevation\", \"view_angle\"]):\n",
    "    df_hist = compute_histogram(col, nbins=30)\n",
    "\n",
    "    ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "    ax.set_title(f\"Histogram of {col.replace('_',' ').title()}\")\n",
    "    ax.set_xlabel(col.replace('_',' ').title())\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05745a81-42e9-4ff2-b7e1-9f9f1ee79912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of Sample Count per Month ---\n",
    "df_monthly = con.execute(\"\"\"\n",
    "    SELECT date_trunc('month', acquired) AS month, COUNT(DISTINCT id) AS sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(df_monthly['month'].astype(str), df_monthly['sample_count'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Sample Count per Month (Unique Scenes)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87f0de-daed-44b7-aa6d-41cae567ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of coverage_pct ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"coverage_pct\", nbins=10)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'coverage_pct'.title()}\")\n",
    "ax.set_xlabel(\"coverage_pct\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd105d2-b778-467e-96c7-fa9cb0a9b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of clear_percent ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"clear_percent\", nbins=30)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'clear_percent'.title()}\")\n",
    "ax.set_xlabel(\"clear_percent\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89867d-353c-4f2e-88a8-4e4f4ff83127",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    grid_id,\n",
    "    MIN(tide_height) AS obs_min_tide_height,\n",
    "    MAX(tide_height) AS obs_max_tide_height\n",
    "FROM samples_all\n",
    "WHERE\n",
    "    acquired >= TIMESTAMP '2023-12-01'\n",
    "    AND acquired <  TIMESTAMP '2025-01-01'\n",
    "    AND item_type        = 'PSScene'\n",
    "    AND publishing_stage = 'finalized'\n",
    "    AND quality_category = 'standard'\n",
    "    AND has_sr_asset\n",
    "    AND ground_control\n",
    "    AND has_tide_data\n",
    "GROUP BY grid_id\n",
    "ORDER BY grid_id;\n",
    "\"\"\"\n",
    "\n",
    "df = con.execute(query).fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_tide = grids_ca.join(df, how=\"left\").dropna(subset=[\"obs_min_tide_height\", \"obs_max_tide_height\", 'tide_range'])\n",
    "geo_tide['obs_tide_range'] = geo_tide.obs_max_tide_height - geo_tide.obs_min_tide_height\n",
    "geo_tide['phase_coverage'] = geo_tide['obs_tide_range'] / geo_tide['tide_range']\n",
    "plot_gdf_column(geo_tide, \"phase_coverage\", title=\"phase_coverage\", show_coastlines=True)\n",
    "\n",
    "hex_tide = (\n",
    "    geo_tide\n",
    "      .groupby(\"hex_id\")\n",
    "      .agg(                 # keep one row per hex_id\n",
    "          obs_min_tide_height=(\"obs_min_tide_height\", \"min\"),   # lowest observed tide\n",
    "          obs_max_tide_height=(\"obs_max_tide_height\", \"max\"),   # highest observed tide\n",
    "          tide_min=(\"tide_min\", \"min\"),   # lowest tide\n",
    "          tide_max=(\"tide_max\", \"max\"),   # highest tide\n",
    "      )\n",
    ")\n",
    "hex_tide['tide_range'] = hex_tide.tide_max - hex_tide.tide_min\n",
    "hex_tide['obs_tide_range'] = hex_tide.obs_max_tide_height - hex_tide.obs_min_tide_height\n",
    "hex_tide['phase_coverage'] = hex_tide.obs_tide_range / hex_tide.tide_range\n",
    "\n",
    "hex_tide = hex_tide[hex_tide.index >= 0]\n",
    "hex_tide = hex_tide.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(hex_tide, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"phase_coverage\", title=\"phase_coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d39a36-7831-4b9c-9f43-217e332084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "-- one row per grid_id × calendar-month\n",
    "SELECT\n",
    "    grid_id,\n",
    "    /* month_start = first day of the month, keeps it sortable & readable */\n",
    "    DATE_TRUNC('month', acquired) AS month_start,\n",
    "    COUNT(*)                       AS sample_count,\n",
    "    COUNT_IF(has_8_channel)        AS count_8_channel      -- rows where flag = TRUE\n",
    "FROM samples_all\n",
    "WHERE\n",
    "    item_type        = 'PSScene'\n",
    "    AND coverage_pct > 0.5\n",
    "GROUP BY grid_id, month_start\n",
    "ORDER BY grid_id, month_start;\n",
    "\"\"\"\n",
    "\n",
    "monthly_counts = con.execute(query).fetchdf().set_index(\"grid_id\")\n",
    "monthly_counts[\"pct_8_channel\"] = monthly_counts.count_8_channel / monthly_counts.sample_count\n",
    "monthly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046af43-fa6d-417d-b0e4-2f2257e7c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts.loc[12487145].plot.scatter(y=\"pct_8_channel\", x=\"month_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2903f-b922-40ba-8231-754f3f765ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts.loc[12487145].plot.scatter(y=\"sample_count\", x=\"month_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d98cee-d9f0-480f-bb88-f29e0241d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_month_8_channel = monthly_counts[monthly_counts.pct_8_channel > 0.5].reset_index().drop_duplicates(subset=[\"grid_id\"]).set_index(\"grid_id\")\n",
    "first_month_8_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1dc557-119d-45e9-86ee-052901fcd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tide = grids_ca.join(first_month_8_channel[[\"month_start\"]], how=\"left\").dropna(subset=['month_start'])\n",
    "plot_gdf_column(geo_tide, \"month_start\", title=\"month_start\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56896a48-f5a6-4c53-89d7-ca717003b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_counts = grids_ca[[\"hex_id\"]].join(monthly_counts, how='left')\n",
    "\n",
    "agg = (\n",
    "    hex_counts.groupby(['hex_id', 'month_start'], as_index=False, sort=False)[['count_8_channel', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          pct_8_channel=lambda d: d['count_8_channel'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "\n",
    "agg = agg[agg.index >= 0]\n",
    "agg = agg[agg.pct_8_channel > 0.5].reset_index().drop_duplicates(subset=[\"hex_id\"]).set_index(\"hex_id\")\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"month_start\", title=\"month_start\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091101e-1101-487b-a6ed-0589c48ab0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_paths = sorted(list(Path(\"/Users/kyledorman/data/planet_coverage/figs/points_30km/days_with_sample/\").glob(\"max_*valid*\")))[:-1]\n",
    "\n",
    "def make_gif(image_paths):\n",
    "    frames = [Image.open(image) for image in image_paths]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(\"/Users/kyledorman/data/planet_coverage/figs/points_30km/days_with_sample/max_days_with_sample_valid.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=700, loop=0)\n",
    "    \n",
    "make_gif(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af97e0-8774-4230-a4ce-adb1329d59de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
