{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997513c2-5c95-4bb9-944e-c1d7379903d8",
   "metadata": {},
   "source": [
    "# DuckDB + Parquet Data Exploration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8991d-9b51-4869-8aa1-7199bd7cc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colors, ticker\n",
    "from typing import Optional, Tuple\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import folium\n",
    "import matplotlib.dates as mdates\n",
    "from random import shuffle\n",
    "\n",
    "from src.gen_points_map import compute_step, make_equal_area_hex_grid, make_equal_area_grid\n",
    "from src.geo_util import assign_intersection_id\n",
    "from src.plotting.util import plot_gdf_column, load_grids\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # hide every warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c1bcc-9ee6-4bcd-ad50-6cb1925c9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_paths = sorted(list(Path(\"/Users/kyledorman/data/planet_coverage/figs/points_30km/days_with_sample/\").glob(\"max_*valid*\")))[:-1]\n",
    "\n",
    "def make_gif(image_paths):\n",
    "    frames = [Image.open(image) for image in image_paths]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(\"/Users/kyledorman/data/planet_coverage/figs/points_30km/days_with_sample/max_days_with_sample_valid.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=700, loop=0)\n",
    "    \n",
    "make_gif(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8fff9-14d0-46f0-86a6-826aa299b5f8",
   "metadata": {},
   "source": [
    "# --- Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7d488-22fa-4e4f-8f03-75b024e60d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"/Users/kyledorman/data/planet_coverage/points_30km/\")  # <-- update this\n",
    "\n",
    "# Example path patterns\n",
    "f_pattern = \"*/coastal_results/*/*/*/coastal_points.parquet\"\n",
    "all_files_pattern = str(BASE / f_pattern)\n",
    "\n",
    "# Combined list used later when we search individual files\n",
    "all_parquets = list(BASE.glob(f_pattern))\n",
    "\n",
    "FILE = all_parquets[0]\n",
    "\n",
    "len(all_parquets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f78e9-07c5-4468-98d7-3667c1958238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_df, grids_df, hex_grid = load_grids(BASE.parent / \"shorelines\")\n",
    "\n",
    "MIN_DIST = 20.0\n",
    "valid = ~grids_df.is_land & (grids_df.dist_km.isna() | (grids_df.dist_km < MIN_DIST))\n",
    "grids_df = grids_df[valid].copy()\n",
    "\n",
    "local_crop = gpd.read_file(BASE.parent / \"shorelines\" / \"la.geojson\")\n",
    "\n",
    "# Filter grids to CA region\n",
    "query_local = query_df[query_df.geometry.intersects(local_crop.union_all())]\n",
    "grids_local = grids_df[grids_df.geometry.intersects(query_local.union_all())]\n",
    "hex_grid_local = hex_grid[hex_grid.geometry.intersects(query_local.union_all())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929171dd-9ced-4508-b24a-cf1c6c1b3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect to DuckDB ---\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7262dee-6b6f-4fa2-ad49-d84fc7b20173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for all files\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_all AS\n",
    "    SELECT * FROM read_parquet('{all_files_pattern}');\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdecbcf-919b-4c11-93b3-03dd314cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a view for a single file for faster iteration\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW samples_one AS\n",
    "    SELECT * FROM '{FILE}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07135270-ac2b-4a82-8477-d26dc4c18fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schema Inspection ---\n",
    "print(\"Schema of samples_one:\")\n",
    "df = con.execute(\"DESCRIBE samples_one\").fetchdf()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19424005-c171-4b68-ac72-e4031acfd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preview Data ---\n",
    "df_preview = con.execute(\"SELECT * FROM samples_one LIMIT 5\").fetchdf()\n",
    "df_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74743f6e-154a-4279-90bc-395e27edaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter By Time ---\n",
    "df_2024 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM samples_one\n",
    "    WHERE acquired >= '2024-01-01' AND acquired < '2025-01-01'\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "df_2024.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d12ad0-8faa-4903-addb-1b3094e99f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter By Time ---\n",
    "df_2024 = con.execute(\"\"\"\n",
    "    SELECT MIN(acquired) as first_sample,\n",
    "    FROM samples_all\n",
    "\"\"\").fetchdf()\n",
    "df_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52eef1-2da7-4444-ab8d-e4c1dbb2a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        grid_id, \n",
    "        cell_id,\n",
    "        MIN(acquired) as first_sample,\n",
    "        MAX(acquired) as last_sample\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id, cell_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "print(df_dates.first_sample.min(), df_dates.first_sample.max())\n",
    "print(df_dates.last_sample.min(), df_dates.last_sample.max())\n",
    "print(len(df_dates), len(grids_df))\n",
    "print(len(df_dates.cell_id.unique()), len(query_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5c8f-5dbb-4de2-90fd-6f377556bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "plot_gdf_column(geo_plot, \"sample_count\", title=\"Sample Count PSScene\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118ada5-0a9d-4d6b-a0a1-4da03463fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "df = pd.DataFrame(geo_plot.groupby(\"hex_id\")[\"sample_count\"].sum())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"sample_count\", title=\"Sample Count PSScene Hex\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdec9ac-6a68-4ec2-94c5-6ae83513fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grids_df.groupby(\"hex_id\")[\"dist_km\"].median())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"dist_km\", title=\"dist_km\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a3de4-7d51-476f-bceb-2dd906eb2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "# Sample count per grid cell\n",
    "df_counts = con.execute(\"\"\"\n",
    "    SELECT grid_id, COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    AND coverage_pct > 0.5\n",
    "    AND publishing_stage = 'finalized'\n",
    "    AND quality_category = 'standard'\n",
    "    AND has_sr_asset\n",
    "    AND ground_control\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_plot = grids_ca.join(df_counts, how=\"left\").fillna({\"sample_count\": 0})\n",
    "\n",
    "df = pd.DataFrame(geo_plot.groupby(\"hex_id\")[\"sample_count\"].sum())\n",
    "df = df[df.index >= 0]\n",
    "df = df.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"sample_count\", title=\"High Quality Sample Count\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63125f-cf35-46fa-8240-f3684d73c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id, SUM(coverage_pct > 0.5)::DOUBLE AS coverage_count,  COUNT(*) as sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_coverage = grids_ca.join(df, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% Greater than 50% coverage\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% Greater than 50% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23e987-12c0-43f2-928a-60dcf8dda32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE as coverage_count,\n",
    "           COUNT(*) AS sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_coverage = grids_ca.join(df_pct, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% Intersects Grid Center\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% Intersects Grid Center\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c2552-ed47-4270-b1bd-e68248d157b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE  / SUM(coverage_pct > 0.5)::DOUBLE AS frac_coverage\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_pct = grids_ca.join(df_pct, how=\"left\").fillna({\"frac_coverage\": 0.0})\n",
    "\n",
    "plot_gdf_column(geo_pct, \"frac_coverage\", title=\"Ration grid center vs 50% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46113e-82c6-49df-8c4d-23a5d39ae83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Geo Points and Join ---\n",
    "\n",
    "df_pct = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT grid_id,\n",
    "           SUM(intersects_grid_centroid)::DOUBLE  / SUM(coverage_pct > 0.75)::DOUBLE AS frac_coverage\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY grid_id\n",
    "\"\"\"\n",
    ").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_pct = grids_ca.join(df_pct, how=\"left\").fillna({\"frac_coverage\": 0.0})\n",
    "\n",
    "plot_gdf_column(geo_pct, \"frac_coverage\", title=\"Ration grid center vs 75% coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eff73-4a18-4e0c-9385-024d07d04eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cov = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        grid_id,\n",
    "        COUNT(*)                                                  AS sample_count,\n",
    "        SUM(CASE WHEN coverage_pct > 0.5 THEN 1 ELSE 0 END)      AS coverage_count,\n",
    "    FROM samples_all\n",
    "    WHERE item_type        = 'PSScene'\n",
    "      AND publishing_stage = 'finalized'\n",
    "      AND quality_category = 'standard'\n",
    "      AND has_sr_asset\n",
    "      AND ground_control\n",
    "    GROUP BY grid_id\n",
    "\"\"\").fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "# join with your coastal grid GeoDataFrame\n",
    "geo_coverage = grids_ca.join(df_cov, how=\"left\").fillna({\"sample_count\": 1.0, \"coverage_count\": 0.0})\n",
    "geo_coverage[\"sample_pct\"] = geo_coverage.coverage_count / geo_coverage.sample_count \n",
    "\n",
    "plot_gdf_column(geo_coverage, \"sample_pct\", title=\"% of high quality captures with >50 % area\", show_coastlines=True)\n",
    "\n",
    "agg = (\n",
    "    geo_coverage.groupby('hex_id', as_index=False, sort=False)[['coverage_count', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          coverage_pct=lambda d: d['coverage_count'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "agg = agg.set_index(\"hex_id\")[agg.index >= 0]\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"coverage_pct\", title=\"% of high quality captures with >50 % area\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497b136-bbf1-4abf-b565-2c9f10eaa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Histogram Per Day Counts (w/Publish Stage) ---- #\n",
    "\n",
    "# 1. Pull per-day counts broken out by stage\n",
    "df_stage = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        date_trunc('day', acquired) AS day,\n",
    "        publishing_stage,\n",
    "        COUNT(DISTINCT id) AS cnt\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY day, publishing_stage\n",
    "    ORDER BY day\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# 2. Normalize day column and pivot so each stage is its own column\n",
    "df_stage['day'] = pd.to_datetime(df_stage['day']).dt.date\n",
    "df_pivot = (\n",
    "    df_stage\n",
    "    .pivot(index='day', columns='publishing_stage', values='cnt')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 3. Ensure a consistent stack order\n",
    "stages = ['preview', 'finalized', 'standard']\n",
    "df_pivot = df_pivot.reindex(columns=stages, fill_value=0)\n",
    "\n",
    "# 4. Plot stacked bars\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "bottom = np.zeros(len(df_pivot))\n",
    "\n",
    "for stage in stages:\n",
    "    ax.bar(\n",
    "        df_pivot.index.astype(str),\n",
    "        df_pivot[stage],\n",
    "        bottom=bottom,\n",
    "        label=stage\n",
    "    )\n",
    "    bottom += df_pivot[stage].values\n",
    "\n",
    "ax.set_xticklabels(df_pivot.index.astype(str), rotation=45, ha='right')\n",
    "ax.set_title(\"Sample Count per Day by Publishing Stage\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"Sample Count\")\n",
    "ax.legend(title=\"Publishing Stage\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d116df9-8fe2-4519-8488-4cdabc72e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minmax(column: str) -> pd.DataFrame:\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "        MIN({column}) AS minv,\n",
    "        MAX({column}) AS maxv\n",
    "        FROM samples_all\n",
    "        WHERE item_type = 'PSScene'\n",
    "    \"\"\"\n",
    "    return con.execute(sql).fetchdf()\n",
    "\n",
    "def compute_histogram(column: str, nbins: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs DuckDB's histogram() table function on `column` in samples_all (filtered to PSScene)\n",
    "    and returns a DataFrame with columns: bin_upper, frequency.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        WITH bounds AS (\n",
    "          SELECT\n",
    "            MIN({column}) AS mn,\n",
    "            MAX({column}) AS mx\n",
    "          FROM samples_all\n",
    "          WHERE item_type = 'PSScene'\n",
    "        )\n",
    "        SELECT\n",
    "          -- histogram() returns a MAP<upper_boundary, count>\n",
    "          histogram(\n",
    "            {column},\n",
    "            equi_width_bins(bounds.mn::DOUBLE, bounds.mx::DOUBLE, {nbins}::BIGINT, True)\n",
    "          ) AS hist_map\n",
    "        FROM samples_all\n",
    "        CROSS JOIN bounds\n",
    "        WHERE item_type = 'PSScene';\n",
    "    \"\"\"\n",
    "    hist_map = con.execute(sql).fetchdf().iloc[0][\"hist_map\"]\n",
    "\n",
    "    \n",
    "    # Unpack into a two-column DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'bin_upper': list(hist_map.keys()),\n",
    "        'count':     list(hist_map.values())\n",
    "    })\n",
    "    df = df.sort_values('bin_upper').reset_index(drop=True)\n",
    "    uppers = df['bin_upper'].tolist()\n",
    "    bin_size = uppers[1] - uppers[0]\n",
    "    # Compute lower edge from previous upper\n",
    "    lowest = uppers[0] - bin_size\n",
    "    lowers = [lowest] + uppers[:-1]\n",
    "    df[\"bin_lower\"] = pd.Series(lowers)\n",
    "    df[\"centers\"] = (df[\"bin_lower\"] + df['bin_upper']) / 2\n",
    "    df[\"widths\"]  = df['bin_upper'] - df[\"bin_lower\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a1c51-6cc6-4b48-84ff-208eaa737f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 2×2 grid of histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# 2. Plotting all four angle columns\n",
    "for ax, col in zip(axes, [\"satellite_azimuth\", \"sun_azimuth\", \"sun_elevation\", \"view_angle\"]):\n",
    "    df_hist = compute_histogram(col, nbins=30)\n",
    "\n",
    "    ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "    ax.set_title(f\"Histogram of {col.replace('_',' ').title()}\")\n",
    "    ax.set_xlabel(col.replace('_',' ').title())\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05745a81-42e9-4ff2-b7e1-9f9f1ee79912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of Sample Count per Month ---\n",
    "df_monthly = con.execute(\"\"\"\n",
    "    SELECT date_trunc('month', acquired) AS month, COUNT(DISTINCT id) AS sample_count\n",
    "    FROM samples_all\n",
    "    WHERE item_type = 'PSScene'\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(df_monthly['month'].astype(str), df_monthly['sample_count'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Sample Count per Month (Unique Scenes)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87f0de-daed-44b7-aa6d-41cae567ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of coverage_pct ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"coverage_pct\", nbins=10)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'coverage_pct'.title()}\")\n",
    "ax.set_xlabel(\"coverage_pct\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd105d2-b778-467e-96c7-fa9cb0a9b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of clear_percent ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "df_hist = compute_histogram(\"clear_percent\", nbins=30)\n",
    "\n",
    "ax.bar(df_hist[\"centers\"], df_hist['count'], width=df_hist[\"widths\"] * 0.9)\n",
    "ax.set_title(f\"Histogram of {'clear_percent'.title()}\")\n",
    "ax.set_xlabel(\"clear_percent\".title())\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89867d-353c-4f2e-88a8-4e4f4ff83127",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    grid_id,\n",
    "    MIN(tide_height) AS obs_min_tide_height,\n",
    "    MAX(tide_height) AS obs_max_tide_height\n",
    "FROM samples_all\n",
    "WHERE\n",
    "    acquired >= TIMESTAMP '2023-12-01'\n",
    "    AND acquired <  TIMESTAMP '2025-01-01'\n",
    "    AND item_type        = 'PSScene'\n",
    "    AND publishing_stage = 'finalized'\n",
    "    AND quality_category = 'standard'\n",
    "    AND has_sr_asset\n",
    "    AND ground_control\n",
    "    AND has_tide_data\n",
    "GROUP BY grid_id\n",
    "ORDER BY grid_id;\n",
    "\"\"\"\n",
    "\n",
    "df = con.execute(query).fetchdf().set_index(\"grid_id\")\n",
    "\n",
    "geo_tide = grids_ca.join(df, how=\"left\").dropna(subset=[\"obs_min_tide_height\", \"obs_max_tide_height\", 'tide_range'])\n",
    "geo_tide['obs_tide_range'] = geo_tide.obs_max_tide_height - geo_tide.obs_min_tide_height\n",
    "geo_tide['phase_coverage'] = geo_tide['obs_tide_range'] / geo_tide['tide_range']\n",
    "plot_gdf_column(geo_tide, \"phase_coverage\", title=\"phase_coverage\", show_coastlines=True)\n",
    "\n",
    "hex_tide = (\n",
    "    geo_tide\n",
    "      .groupby(\"hex_id\")\n",
    "      .agg(                 # keep one row per hex_id\n",
    "          obs_min_tide_height=(\"obs_min_tide_height\", \"min\"),   # lowest observed tide\n",
    "          obs_max_tide_height=(\"obs_max_tide_height\", \"max\"),   # highest observed tide\n",
    "          tide_min=(\"tide_min\", \"min\"),   # lowest tide\n",
    "          tide_max=(\"tide_max\", \"max\"),   # highest tide\n",
    "      )\n",
    ")\n",
    "hex_tide['tide_range'] = hex_tide.tide_max - hex_tide.tide_min\n",
    "hex_tide['obs_tide_range'] = hex_tide.obs_max_tide_height - hex_tide.obs_min_tide_height\n",
    "hex_tide['phase_coverage'] = hex_tide.obs_tide_range / hex_tide.tide_range\n",
    "\n",
    "hex_tide = hex_tide[hex_tide.index >= 0]\n",
    "hex_tide = hex_tide.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(hex_tide, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"phase_coverage\", title=\"phase_coverage\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d39a36-7831-4b9c-9f43-217e332084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "-- one row per grid_id × calendar-month\n",
    "SELECT\n",
    "    grid_id,\n",
    "    /* month_start = first day of the month, keeps it sortable & readable */\n",
    "    DATE_TRUNC('month', acquired) AS month_start,\n",
    "    COUNT(*)                       AS sample_count,\n",
    "    COUNT_IF(has_8_channel)        AS count_8_channel      -- rows where flag = TRUE\n",
    "FROM samples_all\n",
    "WHERE\n",
    "    item_type        = 'PSScene'\n",
    "    AND coverage_pct > 0.5\n",
    "GROUP BY grid_id, month_start\n",
    "ORDER BY grid_id, month_start;\n",
    "\"\"\"\n",
    "\n",
    "monthly_counts = con.execute(query).fetchdf().set_index(\"grid_id\")\n",
    "monthly_counts[\"pct_8_channel\"] = monthly_counts.count_8_channel / monthly_counts.sample_count\n",
    "monthly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046af43-fa6d-417d-b0e4-2f2257e7c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts.loc[12487145].plot.scatter(y=\"pct_8_channel\", x=\"month_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2903f-b922-40ba-8231-754f3f765ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts.loc[12487145].plot.scatter(y=\"sample_count\", x=\"month_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d98cee-d9f0-480f-bb88-f29e0241d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_month_8_channel = monthly_counts[monthly_counts.pct_8_channel > 0.5].reset_index().drop_duplicates(subset=[\"grid_id\"]).set_index(\"grid_id\")\n",
    "first_month_8_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1dc557-119d-45e9-86ee-052901fcd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tide = grids_ca.join(first_month_8_channel[[\"month_start\"]], how=\"left\").dropna(subset=['month_start'])\n",
    "plot_gdf_column(geo_tide, \"month_start\", title=\"month_start\", show_coastlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56896a48-f5a6-4c53-89d7-ca717003b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_counts = grids_ca[[\"hex_id\"]].join(monthly_counts, how='left')\n",
    "\n",
    "agg = (\n",
    "    hex_counts.groupby(['hex_id', 'month_start'], as_index=False, sort=False)[['count_8_channel', 'sample_count']]\n",
    "      .sum()                                # ← sums within each hex\n",
    "      .assign(\n",
    "          pct_8_channel=lambda d: d['count_8_channel'] / d['sample_count']  # or * 100 for %\n",
    "      )\n",
    ")\n",
    "\n",
    "agg = agg[agg.index >= 0]\n",
    "agg = agg[agg.pct_8_channel > 0.5].reset_index().drop_duplicates(subset=[\"hex_id\"]).set_index(\"hex_id\")\n",
    "agg = agg.join(hex_grid_ca[[\"geometry\"]])\n",
    "gdf = gpd.GeoDataFrame(agg, geometry=\"geometry\")\n",
    "\n",
    "plot_gdf_column(gdf, \"month_start\", title=\"month_start\", show_coastlines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
